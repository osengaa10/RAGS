{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c6d018a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import together\n",
    "import shutil\n",
    "import logging\n",
    "import time\n",
    "from typing import Any, Dict, List, Mapping, Optional\n",
    "\n",
    "from pydantic import Extra, Field, root_validator, model_validator\n",
    "\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "from langchain.llms.base import LLM\n",
    "from langchain.llms.utils import enforce_stop_tokens\n",
    "from langchain.utils import get_from_dict_or_env\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55e51fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89 models available\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# set your API key\n",
    "os.environ[\"TOGETHER_API_KEY\"] = \"\"\n",
    "together.api_key = os.environ[\"TOGETHER_API_KEY\"]\n",
    "\n",
    "# list available models and descriptons\n",
    "models = together.Models.list()\n",
    "print(f\"{len(models)} models available\")\n",
    "\n",
    "# # print the first 10 models on the menu\n",
    "# model_names = [model_dict['name'] for model_dict in models]\n",
    "# model_names[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "726d25b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89 models available\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64e831864b84b428b8d322d0',\n",
       "  'name': 'Austism/chronos-hermes-13b',\n",
       "  'display_name': 'Chronos Hermes (13B)',\n",
       "  'display_type': 'chat',\n",
       "  'description': 'This model is a 75/25 merge of Chronos (13B) and Nous Hermes (13B) models resulting in having a great ability to produce evocative storywriting and follow a narrative.',\n",
       "  'license': 'other',\n",
       "  'creator_organization': 'Austism',\n",
       "  'hardware_label': '2x A100 80GB',\n",
       "  'num_parameters': 13000000000,\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 2048,\n",
       "  'config': {'stop': ['</s>'],\n",
       "   'prompt_format': '### Instruction:\\n{prompt}\\n### Response:\\n'},\n",
       "  'pricing': {'input': 100, 'output': 100, 'hourly': 0},\n",
       "  'created_at': '2023-08-24T17:08:25.379Z',\n",
       "  'update_at': '2023-08-24T17:08:25.379Z',\n",
       "  'access': '',\n",
       "  'link': '',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 2,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0xFA5C96b20a10cAC5d21E095e6F4f8c3CBC2f3527': 1,\n",
       "    '0xa96806eD1168d759DC233DfB636522b72bBbE159': 1},\n",
       "   'asks_updated': '2023-11-02T04:19:51.779025492Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 1.0238051e-12,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 6.403238e-10,\n",
       "   'throughput_out': 8.6991e-11}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '6532f0faf94bacfc629b4cf7',\n",
       "  'name': 'EleutherAI/llemma_7b',\n",
       "  'display_name': 'Llemma (7B)',\n",
       "  'display_type': 'language',\n",
       "  'description': 'Llemma 7B is a language model for mathematics. It was initialized with Code Llama 7B weights, and trained on the Proof-Pile-2 for 200B tokens.',\n",
       "  'license': 'LLaMA license Agreement (Meta)',\n",
       "  'link': 'https://huggingface.co/EleutherAI/llemma_7b',\n",
       "  'creator_organization': 'EleutherAI',\n",
       "  'hardware_label': 'A100 80GB',\n",
       "  'pricing_tier': 'Featured',\n",
       "  'access': 'open',\n",
       "  'num_parameters': 6738546688,\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 4096,\n",
       "  'config': {},\n",
       "  'pricing': {'input': 50, 'output': 50},\n",
       "  'created_at': '2023-10-20T21:28:26.403Z',\n",
       "  'update_at': '2023-10-24T17:42:38.630Z',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0xcFF8989b33958D1640798CD1A7BDc96AF9420C55': 1},\n",
       "   'asks_updated': '2023-11-02T00:06:46.617966387Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 7.4800447e-25,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 3.3660203e-23,\n",
       "   'throughput_out': 6.058836e-23}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '6495ff1212907e072b8aecc1',\n",
       "  'name': 'EleutherAI/pythia-12b-v0',\n",
       "  'display_name': 'Pythia (12B)',\n",
       "  'display_type': 'language',\n",
       "  'description': 'The Pythia Scaling Suite is a collection of models developed to facilitate interpretability research.',\n",
       "  'license': 'apache-2.0',\n",
       "  'link': 'https://huggingface.co/EleutherAI/pythia-12b-v0',\n",
       "  'creator_organization': 'EleutherAI',\n",
       "  'hardware_label': 'A40 48GB',\n",
       "  'pricing_tier': 'supported',\n",
       "  'num_parameters': 12000000000,\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': False,\n",
       "  'context_length': 2048,\n",
       "  'config': {'stop': ['<|endoftext|>']},\n",
       "  'pricing': {'input': 100, 'output': 100, 'hourly': 0},\n",
       "  'created_at': '2023-06-23T20:22:42.091Z',\n",
       "  'update_at': '2023-06-23T20:22:42.091Z',\n",
       "  'access': '',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x6376511C715189a6E25495fb3744a5E419F9e520': 1},\n",
       "   'asks_updated': '2023-11-02T01:37:00.745724734Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 7.4800447e-25,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 3.3660203e-23,\n",
       "   'throughput_out': 6.1336365e-23}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '6495ff1112907e072b8aecbe',\n",
       "  'name': 'EleutherAI/pythia-1b-v0',\n",
       "  'display_name': 'Pythia (1B)',\n",
       "  'display_type': 'language',\n",
       "  'description': 'The Pythia Scaling Suite is a collection of models developed to facilitate interpretability research.',\n",
       "  'license': 'apache-2.0',\n",
       "  'link': 'https://huggingface.co/EleutherAI/pythia-1b-v0',\n",
       "  'creator_organization': 'EleutherAI',\n",
       "  'hardware_label': 'A40 48GB',\n",
       "  'pricing_tier': 'supported',\n",
       "  'num_parameters': 1000000000,\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': False,\n",
       "  'context_length': 2048,\n",
       "  'pricing': {'input': 25, 'output': 25, 'hourly': 0},\n",
       "  'created_at': '2023-06-23T20:22:41.925Z',\n",
       "  'update_at': '2023-06-23T20:22:41.925Z',\n",
       "  'access': '',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0xAB4d9Fb5cC9d29edf6f9c19F47c9E54c7D33431d': 1},\n",
       "   'asks_updated': '2023-11-01T23:48:31.778914087Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 7.4800447e-25,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 3.3660203e-23,\n",
       "   'throughput_out': 5.9840357e-23}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '6495ff1112907e072b8aecbf',\n",
       "  'name': 'EleutherAI/pythia-2.8b-v0',\n",
       "  'display_name': 'Pythia (2.8B)',\n",
       "  'display_type': 'language',\n",
       "  'description': 'The Pythia Scaling Suite is a collection of models developed to facilitate interpretability research.',\n",
       "  'license': 'apache-2.0',\n",
       "  'creator_organization': 'EleutherAI',\n",
       "  'hardware_label': 'A40 48GB',\n",
       "  'num_parameters': 2800000000,\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': False,\n",
       "  'context_length': 2048,\n",
       "  'config': {'stop': ['<|endoftext|>']},\n",
       "  'pricing': {'input': 25, 'output': 25, 'hourly': 0},\n",
       "  'created_at': '2023-06-23T20:22:41.975Z',\n",
       "  'update_at': '2023-06-23T20:22:41.975Z',\n",
       "  'access': '',\n",
       "  'link': '',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x2903afA0159904c4fE9cABF528495bd9eE91A6b1': 1},\n",
       "   'asks_updated': '2023-11-02T11:36:28.381424069Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 7.4800447e-25,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 3.3660203e-23,\n",
       "   'throughput_out': 6.1336365e-23}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '6495ff1212907e072b8aecc0',\n",
       "  'name': 'EleutherAI/pythia-6.9b',\n",
       "  'display_name': 'Pythia (6.9B)',\n",
       "  'display_type': 'language',\n",
       "  'description': 'The Pythia Scaling Suite is a collection of models developed to facilitate interpretability research.',\n",
       "  'license': 'apache-2.0',\n",
       "  'creator_organization': 'EleutherAI',\n",
       "  'hardware_label': 'A40 48GB',\n",
       "  'pricing_tier': 'featured',\n",
       "  'num_parameters': 6900000000,\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': False,\n",
       "  'context_length': 2048,\n",
       "  'config': {'stop': ['<|endoftext|>']},\n",
       "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
       "  'created_at': '2023-06-23T20:22:42.044Z',\n",
       "  'update_at': '2023-06-23T20:22:42.044Z',\n",
       "  'access': '',\n",
       "  'link': '',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0xBE2A33177Ca1a8AD6b2e04c713372eA2ec412B8E': 1},\n",
       "   'asks_updated': '2023-11-02T00:32:17.078955213Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 7.4800447e-25,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 3.3660203e-23,\n",
       "   'throughput_out': 6.1336365e-23}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64f78861d683768020b9f005',\n",
       "  'name': 'Gryphe/MythoMax-L2-13b',\n",
       "  'display_name': 'MythoMax-L2 (13B)',\n",
       "  'display_type': 'chat',\n",
       "  'description': 'MythoLogic-L2 and Huginn merge using a highly experimental tensor type merge technique. The main difference with MythoMix is that I allowed more of Huginn to intermingle with the single tensors located at the front and end of a model',\n",
       "  'license': 'other',\n",
       "  'creator_organization': 'Gryphe',\n",
       "  'hardware_label': '1x A40 48GB',\n",
       "  'num_parameters': 13000000000,\n",
       "  'release_date': '2023-08-01T00:00:00.000Z',\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 4096,\n",
       "  'config': {'stop': ['</s>'],\n",
       "   'prompt_format': '### Instruction:\\n{prompt}\\n### Response:'},\n",
       "  'pricing': {'input': 100, 'output': 100, 'hourly': 0},\n",
       "  'created_at': '2023-09-05T19:58:25.683Z',\n",
       "  'update_at': '2023-09-05T19:58:25.683Z',\n",
       "  'access': '',\n",
       "  'link': '',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 76,\n",
       "   'num_bids': 73,\n",
       "   'num_running': 73,\n",
       "   'asks': {'0x15846A59498a78D2A8D0C15f5c7a13650023C60F': 1,\n",
       "    '0x198F92E71684261163Ab5D6c0b7d6582dDD1ed39': 1,\n",
       "    '0x300321B1e9037232D6C71e46b1faAc97479c46dc': 2,\n",
       "    '0x5806ad40083a9f481D9a22f7A3940624F3d509c2': 6,\n",
       "    '0x5aa88070b95d50788651e12Fbd0818419f1506d9': 4,\n",
       "    '0x6708BBd8766db4Bd73E96A7E432b7003F51D7Ad1': 6,\n",
       "    '0x67aF66d2468F0D1C45646726682a066C32521F8a': 13,\n",
       "    '0x777C0C19864a1AeE6291E7D2C56f7c00121345D8': 10,\n",
       "    '0x79Db9E75bFEf2a6fD2cd63c78b8fBc339f9e6a8C': 5,\n",
       "    '0x86e28C5FdFbc1BCB00983851B55024955B13324D': 4,\n",
       "    '0xE76A002FcaF4b4A346baC20ACD4B270d32f54a4F': 13,\n",
       "    '0xE9A76B203D041a4f4B75755C229350993997F014': 8,\n",
       "    '0xf15B5E0a54454d930Ea860860bF63c50F48C0c8c': 3},\n",
       "   'asks_updated': '2023-11-02T19:37:02.255973826Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 5.0535927,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 14167.376,\n",
       "   'throughput_out': 2892.3044}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64acefbe227f790586239d40',\n",
       "  'name': 'HuggingFaceH4/starchat-alpha',\n",
       "  'display_name': 'StarCoderChat Alpha (16B)',\n",
       "  'display_type': 'chat',\n",
       "  'description': 'Fine-tuned from StarCoder to act as a helpful coding assistant. As an alpha release is only intended for educational or research purpopses.',\n",
       "  'license': 'bigcode-openrail-m',\n",
       "  'link': 'https://huggingface.co/HuggingFaceH4/starchat-alpha',\n",
       "  'creator_organization': 'HuggingFaceH4',\n",
       "  'hardware_label': 'A40 48GB',\n",
       "  'pricing_tier': 'supported',\n",
       "  'num_parameters': 16000000000,\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': False,\n",
       "  'context_length': 8192,\n",
       "  'config': {'stop': ['<|endoftext|>', '<|end|>'],\n",
       "   'prompt_format': '<|system|>\\n<|end|>\\n<|user|>\\n{prompt}<|end|>\\n<|assistant|>'},\n",
       "  'pricing': {'input': 100, 'output': 100, 'hourly': 0},\n",
       "  'created_at': '2023-07-11T05:59:26.298Z',\n",
       "  'update_at': '2023-07-11T05:59:26.298Z',\n",
       "  'access': '',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x001fd7d3dCf2085A17fE9B6499180Eca87abB7cE': 1},\n",
       "   'asks_updated': '2023-11-02T01:40:00.678892947Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 4.5368766e-25,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 3.266551e-23,\n",
       "   'throughput_out': 2.5860195e-23}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64acebb2227f790586239d16',\n",
       "  'name': 'NousResearch/Nous-Hermes-13b',\n",
       "  'display_name': 'Nous Hermes (13B)',\n",
       "  'display_type': 'language',\n",
       "  'description': 'LLaMA 13B fine-tuned on over 300,000 instructions. Designed for long responses, low hallucination rate, and absence of censorship mechanisms.',\n",
       "  'license': 'gpl, LLaMA License Agreement (Meta)',\n",
       "  'link': 'https://huggingface.co/NousResearch/Nous-Hermes-13b',\n",
       "  'creator_organization': 'Nous Research',\n",
       "  'hardware_label': 'A40 48GB',\n",
       "  'pricing_tier': 'supported',\n",
       "  'access': 'open',\n",
       "  'num_parameters': 13000000000,\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': False,\n",
       "  'context_length': 2048,\n",
       "  'pricing': {'input': 100, 'output': 100, 'hourly': 0},\n",
       "  'created_at': '2023-07-11T05:42:10.444Z',\n",
       "  'update_at': '2023-07-11T05:42:10.444Z',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x7cA1082c90A01Cd7E42637751E76c7a6325D5aFD': 1},\n",
       "   'asks_updated': '2023-11-02T10:58:18.437065467Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 8.836629e-25,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 3.9764828e-23,\n",
       "   'throughput_out': 7.1576695e-23}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64cae18d3ede2fa7e2cbcc7d',\n",
       "  'name': 'NousResearch/Nous-Hermes-Llama2-13b',\n",
       "  'display_name': 'Nous Hermes Llama-2 (13B)',\n",
       "  'display_type': 'chat',\n",
       "  'description': 'Nous-Hermes-Llama2-13b is a state-of-the-art language model fine-tuned on over 300,000 instructions.',\n",
       "  'license': 'mit',\n",
       "  'creator_organization': 'Nous Research',\n",
       "  'hardware_label': '2x A100 80GB',\n",
       "  'pricing_tier': 'featured',\n",
       "  'access': 'open',\n",
       "  'num_parameters': 13000000000,\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 4096,\n",
       "  'config': {'prompt_format': '### Instruction:\\n{prompt}\\n### Response:\\n',\n",
       "   'stop': ['###', '</s>']},\n",
       "  'pricing': {'input': 100, 'output': 100, 'hourly': 0},\n",
       "  'created_at': '2023-08-02T23:06:53.926Z',\n",
       "  'update_at': '2023-10-07T00:19:33.779Z',\n",
       "  'link': '',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 70,\n",
       "   'num_bids': 65,\n",
       "   'num_running': 65,\n",
       "   'asks': {'0x3167189Cd107b0DB695b25a871c00C0db9ef057a': 8,\n",
       "    '0x48C9Ebb5550B356Bfc5Fd7A3010de8a7aD310eBd': 7,\n",
       "    '0xAf76D0269f0B94aCAC2869cb927e61fe3b8Bc989': 8,\n",
       "    '0xB00F7CF7434bD60C75f8e9367C983933C14CD2bC': 8,\n",
       "    '0xB9EC1C815fDdC7F8B1A9D7190dF07467F2733251': 8,\n",
       "    '0xe8B003766022e57D0aEe9ab5Fc97A0892AB2832d': 23,\n",
       "    '0xee83Ba352e9b2539ff0aAB19C406ACcAa53ce187': 8},\n",
       "   'asks_updated': '2023-11-02T11:19:11.058468406Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 15.738876,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 81422.375,\n",
       "   'throughput_out': 2703.604}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '6532f0faf94bacfc629b4cf8',\n",
       "  'name': 'NousResearch/Nous-Hermes-Llama2-70b',\n",
       "  'display_name': 'Nous Hermes LLaMA-2 (70B)',\n",
       "  'display_type': 'chat',\n",
       "  'description': 'Nous-Hermes-Llama2-70b is a state-of-the-art language model fine-tuned on over 300,000 instructions.',\n",
       "  'license': 'LLaMA license Agreement (Meta)',\n",
       "  'link': 'https://huggingface.co/NousResearch/Nous-Hermes-Llama2-70b',\n",
       "  'creator_organization': 'NousResearch',\n",
       "  'hardware_label': '2X A100 80GB',\n",
       "  'pricing_tier': 'Featured',\n",
       "  'access': 'open',\n",
       "  'num_parameters': 70000000000,\n",
       "  'show_in_playground': True,\n",
       "  'context_length': 4096,\n",
       "  'config': {'stop': ['###', '</s>'],\n",
       "   'prompt_format': '### Instruction:\\n{prompt}\\n\\n### Response:\\n'},\n",
       "  'pricing': {'input': 250, 'output': 250},\n",
       "  'created_at': '2023-10-20T21:28:26.404Z',\n",
       "  'update_at': '2023-10-24T17:43:39.278Z',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 2,\n",
       "   'num_bids': 1,\n",
       "   'num_running': 1,\n",
       "   'asks': {'0x8a188c150800cB4876DAE688AEAA5C7491cb3Eb8': 2},\n",
       "   'asks_updated': '2023-11-02T01:37:00.778864273Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 0.06307815,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 189.72983,\n",
       "   'throughput_out': 10.118084}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '6532f0faf94bacfc629b4cf6',\n",
       "  'name': 'NousResearch/Nous-Hermes-llama-2-7b',\n",
       "  'display_name': 'Nous Hermes LLaMA-2 (7B)',\n",
       "  'display_type': 'chat',\n",
       "  'description': 'Nous-Hermes-Llama2-7b is a state-of-the-art language model fine-tuned on over 300,000 instructions.',\n",
       "  'license': 'LLaMA license Agreement (Meta)',\n",
       "  'link': 'https://huggingface.co/NousResearch/Nous-Hermes-llama-2-7b',\n",
       "  'creator_organization': 'NousResearch',\n",
       "  'hardware_label': 'A100 80GB',\n",
       "  'pricing_tier': 'Featured',\n",
       "  'access': 'open',\n",
       "  'num_parameters': 6738415616,\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 4096,\n",
       "  'config': {'prompt_format': '### Instruction:\\n{prompt}\\n### Response:\\n',\n",
       "   'stop': ['###', '</s>']},\n",
       "  'pricing': {'input': 50, 'output': 50},\n",
       "  'created_at': '2023-10-20T21:28:26.403Z',\n",
       "  'update_at': '2023-10-24T17:41:52.365Z',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 2,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x0C97271Bd30C44592D70534E2A17CbF213A26f92': 1,\n",
       "    '0xCdaaBCEF813fC6c6AB7D9eB4CF17164Bd2F2A946': 1},\n",
       "   'asks_updated': '2023-11-02T11:29:16.712744031Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 3.982449e-15,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 1.6990352e-11,\n",
       "   'throughput_out': 4.4673626e-13}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64f677bdbc372ce719b97f05',\n",
       "  'name': 'NumbersStation/nsql-llama-2-7B',\n",
       "  'display_name': 'NSQL LLaMA-2 (7B)',\n",
       "  'display_type': 'code',\n",
       "  'description': 'NSQL is a family of autoregressive open-source large foundation models (FMs) designed specifically for SQL generation tasks.',\n",
       "  'license': 'llama2',\n",
       "  'creator_organization': 'Numbers Station',\n",
       "  'hardware_label': 'A40 48GB',\n",
       "  'pricing_tier': 'supported',\n",
       "  'num_parameters': 7000000000,\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 4096,\n",
       "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
       "  'created_at': '2023-09-05T00:35:09.649Z',\n",
       "  'update_at': '2023-09-05T00:35:09.649Z',\n",
       "  'access': '',\n",
       "  'link': '',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0xBb702A9526c057836fe845DF91dEAa3B5a48cc84': 1},\n",
       "   'asks_updated': '2023-11-02T00:44:58.161748195Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 3.296015e-11,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 7.9104356e-10,\n",
       "   'throughput_out': 1.6480074e-10}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '6532f0faf94bacfc629b4cf5',\n",
       "  'name': 'Open-Orca/Mistral-7B-OpenOrca',\n",
       "  'display_name': 'OpenOrca Mistral (7B) 8K',\n",
       "  'display_type': 'chat',\n",
       "  'description': 'An OpenOrca dataset fine-tune on top of Mistral 7B by the OpenOrca team.',\n",
       "  'license': 'apache-2.0',\n",
       "  'link': 'https://huggingface.co/Open-Orca/Mistral-7B-OpenOrca',\n",
       "  'creator_organization': 'OpenOrca',\n",
       "  'hardware_label': 'A100 80GB',\n",
       "  'pricing_tier': 'Featured',\n",
       "  'access': 'open',\n",
       "  'num_parameters': 7241748480,\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 8192,\n",
       "  'config': {'stop': ['<|im_end|>'],\n",
       "   'prompt_format': '<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant'},\n",
       "  'pricing': {'input': 50, 'output': 50},\n",
       "  'created_at': '2023-10-20T21:28:26.403Z',\n",
       "  'update_at': '2023-10-24T00:01:52.541Z',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 3,\n",
       "   'num_bids': 1,\n",
       "   'num_running': 1,\n",
       "   'asks': {'0x9520536648CbfC95b46CDF6db45ae6B05E12425C': 2,\n",
       "    '0xe6a7E80Ea4D0C6190ada009e23f9cc53b36B030a': 1},\n",
       "   'asks_updated': '2023-11-02T12:08:50.109499231Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 0.24456033,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 1380.5437,\n",
       "   'throughput_out': 118.948616}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64f67b8ebc372ce719b97f08',\n",
       "  'name': 'OpenAssistant/llama2-70b-oasst-sft-v10',\n",
       "  'display_name': 'LLaMA 2 SFT v10 (70B)',\n",
       "  'display_type': 'chat',\n",
       "  'description': 'An Open-Assistant fine-tuned model from LLaMA-2 70B.',\n",
       "  'license': 'llama2',\n",
       "  'creator_organization': 'OpenAssistant',\n",
       "  'hardware_label': '2x A100 80GB',\n",
       "  'pricing_tier': 'supported',\n",
       "  'access': 'open',\n",
       "  'num_parameters': 70000000000,\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 4096,\n",
       "  'config': {'stop': ['</s>', '<|im_end|>'],\n",
       "   'prompt_format': '<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n'},\n",
       "  'pricing': {'input': 250, 'output': 250, 'hourly': 0},\n",
       "  'created_at': '2023-09-05T00:51:26.888Z',\n",
       "  'update_at': '2023-09-07T01:51:52.883Z',\n",
       "  'link': '',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x122E04D3fF2d430222Ff08F344d8B834c18b3534': 1},\n",
       "   'asks_updated': '2023-11-02T11:19:32.950137755Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 0.001111118,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 0.6866709,\n",
       "   'throughput_out': 0.014444534}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '6495ff1212907e072b8aecc8',\n",
       "  'name': 'OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5',\n",
       "  'display_name': 'Open-Assistant Pythia SFT-4 (12B)',\n",
       "  'display_type': 'chat',\n",
       "  'description': 'Chat-based and open-source assistant. The vision of the project is to make a large language model that can run on a single high-end consumer GPU. ',\n",
       "  'license': 'apache-2.0',\n",
       "  'link': 'https://huggingface.co/OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5',\n",
       "  'creator_organization': 'LAION',\n",
       "  'hardware_label': 'A40 48GB',\n",
       "  'pricing_tier': 'supported',\n",
       "  'num_parameters': 12000000000,\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': False,\n",
       "  'context_length': 2048,\n",
       "  'config': {'stop': ['<|endoftext|>'],\n",
       "   'prompt_format': '<|prompter|>{prompt}<|endoftext|><|assistant|>'},\n",
       "  'pricing': {'input': 100, 'output': 100, 'hourly': 0},\n",
       "  'created_at': '2023-06-23T20:22:42.383Z',\n",
       "  'update_at': '2023-06-23T20:22:42.383Z',\n",
       "  'access': '',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x05335b53C553da8cCeE9A334d7E662877D8110A5': 1},\n",
       "   'asks_updated': '2023-11-01T23:35:40.07935692Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 4.5368766e-25,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 3.266551e-23,\n",
       "   'throughput_out': 3.31192e-23}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '6495ff1212907e072b8aecc9',\n",
       "  'name': 'OpenAssistant/stablelm-7b-sft-v7-epoch-3',\n",
       "  'display_name': 'Open-Assistant StableLM SFT-7 (7B)',\n",
       "  'display_type': 'chat',\n",
       "  'description': 'Chat-based and open-source assistant. The vision of the project is to make a large language model that can run on a single high-end consumer GPU. ',\n",
       "  'license': 'cc-by-sa-4.0',\n",
       "  'link': 'https://huggingface.co/OpenAssistant/stablelm-7b-sft-v7-epoch-3',\n",
       "  'creator_organization': 'LAION',\n",
       "  'hardware_label': 'A40 48GB',\n",
       "  'pricing_tier': 'supported',\n",
       "  'num_parameters': 7000000000,\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': False,\n",
       "  'context_length': 4096,\n",
       "  'config': {'stop': ['<|endoftext|>'],\n",
       "   'prompt_format': '<|prompter|>{prompt}<|endoftext|><|assistant|>'},\n",
       "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
       "  'created_at': '2023-06-23T20:22:42.425Z',\n",
       "  'update_at': '2023-06-23T20:22:42.425Z',\n",
       "  'access': '',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x6e8C6C3A7d42B20b637c8262356984BE92CeE11B': 1},\n",
       "   'asks_updated': '2023-11-02T01:40:00.678915777Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 0,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64fbbc5adfdb1e4b06b5d5cc',\n",
       "  'name': 'Phind/Phind-CodeLlama-34B-Python-v1',\n",
       "  'display_name': 'Phind Code LLaMA Python v1 (34B)',\n",
       "  'display_type': 'code',\n",
       "  'description': 'This model is fine-tuned from CodeLlama-34B-Python and achieves 69.5% pass@1 on HumanEval.',\n",
       "  'license': 'llama2',\n",
       "  'creator_organization': 'Phind',\n",
       "  'hardware_label': 'A100 80GB',\n",
       "  'pricing_tier': 'supported',\n",
       "  'access': 'open',\n",
       "  'num_parameters': 33743970304,\n",
       "  'show_in_playground': 'true',\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 16384,\n",
       "  'config': {'prompt_format': '### Instruction:\\n{prompt}\\n### Response:\\n',\n",
       "   'stop': ['</s>', '###']},\n",
       "  'pricing': {'input': 200, 'output': 200, 'hourly': 0},\n",
       "  'created_at': '2023-09-09T00:29:14.496Z',\n",
       "  'update_at': '2023-09-09T00:29:14.496Z',\n",
       "  'link': '',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x61534598ACEea8a784b6F661c1c5343c050C9Beb': 1},\n",
       "   'asks_updated': '2023-11-02T11:39:10.112769377Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 3.840383e-25,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 3.9555944e-23,\n",
       "   'throughput_out': 1.0753073e-23}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64fbbc5adfdb1e4b06b5d5cb',\n",
       "  'name': 'Phind/Phind-CodeLlama-34B-v2',\n",
       "  'display_name': 'Phind Code LLaMA v2 (34B)',\n",
       "  'display_type': 'code',\n",
       "  'description': 'Phind-CodeLlama-34B-v1 trained on additional 1.5B tokens high-quality programming-related data proficient in Python, C/C++, TypeScript, Java, and more.',\n",
       "  'license': 'llama2',\n",
       "  'creator_organization': 'Phind',\n",
       "  'hardware_label': 'A100 80GB',\n",
       "  'pricing_tier': 'supported',\n",
       "  'access': 'open',\n",
       "  'num_parameters': 33743970304,\n",
       "  'show_in_playground': 'true',\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 16384,\n",
       "  'config': {'prompt_format': '### System Prompt\\nYou are an intelligent programming assistant.\\n\\n### User Message\\n{prompt}n\\n### Assistant\\n',\n",
       "   'stop': ['</s>']},\n",
       "  'pricing': {'input': 200, 'output': 200, 'hourly': 0},\n",
       "  'created_at': '2023-09-09T00:29:14.496Z',\n",
       "  'update_at': '2023-09-09T00:29:14.496Z',\n",
       "  'link': '',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x210A3a729DCE7aDD44E553a5E74c3ba64c64D0d5': 1},\n",
       "   'asks_updated': '2023-11-02T10:58:25.205726919Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 1.8313354e-19,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 1.7842484e-15,\n",
       "   'throughput_out': 2.1572402e-17}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64acee11227f790586239d36',\n",
       "  'name': 'SG161222/Realistic_Vision_V3.0_VAE',\n",
       "  'display_name': 'Realistic Vision 3.0',\n",
       "  'display_type': 'image',\n",
       "  'description': 'Fine-tune version of Stable Diffusion focused on photorealism.',\n",
       "  'license': 'creativeml-openrail-m',\n",
       "  'link': 'https://huggingface.co/SG161222/Realistic_Vision_V1.4',\n",
       "  'creator_organization': 'SG161222',\n",
       "  'hardware_label': 'A40 48GB',\n",
       "  'pricing_tier': 'supported',\n",
       "  'access': 'open',\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'external_pricing_url': 'https://www.together.xyz/apis#pricing',\n",
       "  'config': {'height': 1024,\n",
       "   'width': 1024,\n",
       "   'steps': 20,\n",
       "   'number_of_images': 2,\n",
       "   'seed': 42},\n",
       "  'created_at': '2023-07-11T05:52:17.219Z',\n",
       "  'update_at': '2023-07-11T05:52:17.219Z',\n",
       "  'descriptionLink': '',\n",
       "  'pricing': {'hourly': 0, 'input': 0, 'output': 0, 'base': 0, 'finetune': 0},\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x1E128f472069E38aEF6B8f25147B42EF81f0F3C0': 1},\n",
       "   'asks_updated': '2023-11-02T11:40:46.212822766Z',\n",
       "   'gpus': {'NVIDIA A40': 1},\n",
       "   'options': {'input=text,image': 1},\n",
       "   'qps': 0.0792505,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 9.364233e-05}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64fbbc5adfdb1e4b06b5d5cd',\n",
       "  'name': 'WizardLM/WizardCoder-15B-V1.0',\n",
       "  'display_name': 'WizardCoder v1.0 (15B)',\n",
       "  'display_type': 'code',\n",
       "  'description': 'This model empowers Code LLMs with complex instruction fine-tuning, by adapting the Evol-Instruct method to the domain of code.',\n",
       "  'license': 'llama2',\n",
       "  'creator_organization': 'WizardLM',\n",
       "  'hardware_label': 'A100 80GB',\n",
       "  'pricing_tier': 'supported',\n",
       "  'access': 'open',\n",
       "  'num_parameters': 15517462528,\n",
       "  'show_in_playground': 'true',\n",
       "  'context_length': 8192,\n",
       "  'config': {'prompt_format': '### Instruction:\\n{prompt}\\n\\n### Response:\\n',\n",
       "   'stop': ['###', '<|endoftext|>']},\n",
       "  'pricing': {'input': 100, 'output': 100, 'hourly': 0},\n",
       "  'created_at': '2023-09-09T00:29:14.496Z',\n",
       "  'update_at': '2023-09-09T00:29:14.496Z',\n",
       "  'link': '',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0xE19C38bcfc6F9b20E0630E96a5D91ec75F476AB8': 1},\n",
       "   'asks_updated': '2023-11-02T11:13:21.62938593Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 3.840383e-25,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 3.9555944e-23,\n",
       "   'throughput_out': 1.574557e-23}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64f672e8bc372ce719b97f02',\n",
       "  'name': 'WizardLM/WizardCoder-Python-34B-V1.0',\n",
       "  'display_name': 'WizardCoder Python v1.0 (34B)',\n",
       "  'display_type': 'code',\n",
       "  'description': 'This model empowers Code LLMs with complex instruction fine-tuning, by adapting the Evol-Instruct method to the domain of code.',\n",
       "  'license': 'llama2',\n",
       "  'creator_organization': 'WizardLM',\n",
       "  'hardware_label': '2x A100 80GB',\n",
       "  'pricing_tier': 'supported',\n",
       "  'num_parameters': 34000000000,\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 8192,\n",
       "  'config': {'stop': ['</s>', '###'],\n",
       "   'prompt_format': '### Instruction:\\n{prompt}\\n### Response:\\n'},\n",
       "  'pricing': {'input': 200, 'output': 200, 'hourly': 0},\n",
       "  'created_at': '2023-09-05T00:14:32.365Z',\n",
       "  'update_at': '2023-09-05T00:14:32.365Z',\n",
       "  'access': '',\n",
       "  'link': '',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0xB46CFD10f55D3346823592a25C430d79211CDf69': 1},\n",
       "   'asks_updated': '2023-11-02T01:08:51.179246147Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 7.195547e-10,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 1.03615875e-07,\n",
       "   'throughput_out': 1.9427977e-08}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64f67555bc372ce719b97f03',\n",
       "  'name': 'WizardLM/WizardLM-70B-V1.0',\n",
       "  'display_name': 'WizardLM v1.0 (70B)',\n",
       "  'display_type': 'language',\n",
       "  'description': 'This model achieves a substantial and comprehensive improvement on coding, mathematical reasoning and open-domain conversation capacities.',\n",
       "  'license': 'llama2',\n",
       "  'creator_organization': 'WizardLM',\n",
       "  'hardware_label': '2x A100 80GB',\n",
       "  'pricing_tier': 'supported',\n",
       "  'num_parameters': 70000000000,\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 4096,\n",
       "  'config': {'stop': ['</s>'], 'prompt_format': 'USER: {prompt} ASSISTANT:'},\n",
       "  'pricing': {'input': 250, 'output': 250, 'hourly': 0},\n",
       "  'created_at': '2023-09-05T00:24:53.327Z',\n",
       "  'update_at': '2023-09-05T00:24:53.327Z',\n",
       "  'access': '',\n",
       "  'link': '',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0xB76e844982522e5a37e922a7499F95f2FB4E4EbE': 1},\n",
       "   'asks_updated': '2023-11-02T10:26:28.503681222Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 9.604568e-25,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 4.3220553e-23,\n",
       "   'throughput_out': 7.7796995e-23}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64acef6e227f790586239d3f',\n",
       "  'name': 'bigcode/starcoder',\n",
       "  'display_name': 'StarCoder (16B)',\n",
       "  'display_type': 'code',\n",
       "  'description': 'Trained on 80+ coding languages, uses Multi Query Attention, an 8K context window, and was trained using the Fill-in-the-Middle objective on 1T tokens.',\n",
       "  'license': 'bigcode-openrail-m',\n",
       "  'link': 'https://huggingface.co/bigcode/starcoder',\n",
       "  'creator_organization': 'BigCode',\n",
       "  'hardware_label': 'A100 80GB',\n",
       "  'pricing_tier': 'supported',\n",
       "  'num_parameters': 16000000000,\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': False,\n",
       "  'context_length': 8192,\n",
       "  'config': {'stop': ['<|endoftext|>', '<|end|>']},\n",
       "  'pricing': {'input': 100, 'output': 100, 'hourly': 0},\n",
       "  'created_at': '2023-07-11T05:58:06.486Z',\n",
       "  'update_at': '2023-07-11T05:58:06.486Z',\n",
       "  'access': '',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x991a9178d27Fa2A0645610D41C0666cF4da78b37': 1},\n",
       "   'asks_updated': '2023-11-02T11:36:47.135000355Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 3.533323e-25,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 3.6393227e-23,\n",
       "   'throughput_out': 1.0599969e-23}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '6495ff1112907e072b8aecb8',\n",
       "  'name': 'databricks/dolly-v2-12b',\n",
       "  'display_name': 'Dolly v2 (12B)',\n",
       "  'display_type': 'chat',\n",
       "  'description': 'An instruction-following LLM based on pythia-12b, and trained on ~15k instruction/response fine tuning records generated by Databricks employees.',\n",
       "  'license': 'mit',\n",
       "  'link': 'https://huggingface.co/databricks/dolly-v2-12b',\n",
       "  'creator_organization': 'Databricks',\n",
       "  'hardware_label': 'A40 48GB',\n",
       "  'pricing_tier': 'supported',\n",
       "  'num_parameters': 12000000000,\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': False,\n",
       "  'context_length': 2048,\n",
       "  'config': {'stop': ['### End'],\n",
       "   'prompt_format': '### Instruction:\\n{prompt}\\n### Response:'},\n",
       "  'pricing': {'input': 100, 'output': 100, 'hourly': 0},\n",
       "  'created_at': '2023-06-23T20:22:41.607Z',\n",
       "  'update_at': '2023-06-23T20:22:41.607Z',\n",
       "  'access': '',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 2,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x1c1977eCE14E209b731b12997a1a78De4480Dd01': 1,\n",
       "    '0xe5214d5a25782f36FDF1fBCe90013569dd0a9d8a': 1},\n",
       "   'asks_updated': '2023-11-02T15:37:08.679070873Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 1.5708636e-08,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 2.6547596e-06,\n",
       "   'throughput_out': 3.994706e-05}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '6495ff1112907e072b8aecb6',\n",
       "  'name': 'databricks/dolly-v2-3b',\n",
       "  'display_name': 'Dolly v2 (3B)',\n",
       "  'display_type': 'chat',\n",
       "  'description': 'An instruction-following LLM based on pythia-3b, and trained on ~15k instruction/response fine tuning records generated by Databricks employees.',\n",
       "  'license': 'mit',\n",
       "  'link': 'https://huggingface.co/databricks/dolly-v2-3b',\n",
       "  'creator_organization': 'Databricks',\n",
       "  'hardware_label': 'A40 48GB',\n",
       "  'pricing_tier': 'supported',\n",
       "  'num_parameters': 3000000000,\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': False,\n",
       "  'context_length': 2048,\n",
       "  'config': {'stop': ['### End'],\n",
       "   'prompt_format': '### Instruction:\\n{prompt}\\n### Response:'},\n",
       "  'pricing': {'input': 25, 'output': 25, 'hourly': 0},\n",
       "  'created_at': '2023-06-23T20:22:41.524Z',\n",
       "  'update_at': '2023-06-23T20:22:41.524Z',\n",
       "  'access': '',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 2,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x319B7073E931Ed635dA52EE79444D0B29ccC314D': 1,\n",
       "    '0xB9363317321b4D6489F4F6EA5649Fb561A49a88B': 1},\n",
       "   'asks_updated': '2023-11-02T10:58:19.733851705Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 4.174128e-25,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 3.005372e-23,\n",
       "   'throughput_out': 2.9218894e-23}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '6495ff1112907e072b8aecb7',\n",
       "  'name': 'databricks/dolly-v2-7b',\n",
       "  'display_name': 'Dolly v2 (7B)',\n",
       "  'display_type': 'chat',\n",
       "  'description': 'An instruction-following LLM based on pythia-7b, and trained on ~15k instruction/response fine tuning records generated by Databricks employees.',\n",
       "  'license': 'mit',\n",
       "  'link': 'https://huggingface.co/databricks/dolly-v2-7b',\n",
       "  'creator_organization': 'Databricks',\n",
       "  'hardware_label': 'A40 48GB',\n",
       "  'pricing_tier': 'featured',\n",
       "  'num_parameters': 7000000000,\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': False,\n",
       "  'context_length': 2048,\n",
       "  'config': {'stop': ['### End'],\n",
       "   'prompt_format': '### Instruction:\\n{prompt}\\n### Response:'},\n",
       "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
       "  'created_at': '2023-06-23T20:22:41.565Z',\n",
       "  'update_at': '2023-06-23T20:22:41.565Z',\n",
       "  'access': '',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 2,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0xAc5A2142D60E5a359b6097c4fb21D26896f23d1D': 1,\n",
       "    '0xc707a80317970C32e3fB5Dbe19acc0EF725A7889': 1},\n",
       "   'asks_updated': '2023-11-02T19:44:36.170700582Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 4.174128e-25,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 3.005372e-23,\n",
       "   'throughput_out': 2.9218894e-23}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64f67987bc372ce719b97f07',\n",
       "  'name': 'defog/sqlcoder',\n",
       "  'display_name': 'Sqlcoder (15B)',\n",
       "  'display_type': 'language',\n",
       "  'description': \"Defog's SQLCoder is a state-of-the-art LLM for converting natural language questions to SQL queries, fine-tuned from Bigcode's Starcoder 15B model.\",\n",
       "  'license': 'other',\n",
       "  'creator_organization': 'Defog',\n",
       "  'hardware_label': 'A40 48GB',\n",
       "  'pricing_tier': 'supported',\n",
       "  'access': 'open',\n",
       "  'num_parameters': 15000000000,\n",
       "  'show_in_playground': True,\n",
       "  'context_length': 8192,\n",
       "  'config': {'stop': ['<|endoftext|>'],\n",
       "   'prompt_format': '### Instructions:\\n\\n{prompt}\\n\\n### Response:\\n'},\n",
       "  'pricing': {'input': 100, 'output': 100, 'hourly': 0},\n",
       "  'created_at': '2023-09-05T00:42:47.496Z',\n",
       "  'update_at': '2023-09-05T00:42:47.496Z',\n",
       "  'link': '',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x2Be2964991978B65853c88a7256C27C0e116D7E0': 1},\n",
       "   'asks_updated': '2023-11-02T09:16:16.743958611Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 7.4800447e-25,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 3.3660203e-23,\n",
       "   'throughput_out': 6.1336365e-23}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64f676f7bc372ce719b97f04',\n",
       "  'name': 'garage-bAInd/Platypus2-70B-instruct',\n",
       "  'display_name': 'Platypus2 Instruct (70B)',\n",
       "  'display_type': 'chat',\n",
       "  'description': 'An instruction fine-tuned LLaMA-2 (70B) model by merging Platypus2 (70B) by garage-bAInd and LLaMA-2 Instruct v2 (70B) by upstage.',\n",
       "  'license': 'CC BY-NC-4.0',\n",
       "  'creator_organization': 'garage-bAInd',\n",
       "  'hardware_label': '2x A100 80GB',\n",
       "  'pricing_tier': 'featured',\n",
       "  'num_parameters': 70000000000,\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 4096,\n",
       "  'config': {'stop': ['</s>', '###'],\n",
       "   'prompt_format': '### Instruction:\\n{prompt}\\n### Response:\\n'},\n",
       "  'pricing': {'input': 250, 'output': 250, 'hourly': 0},\n",
       "  'created_at': '2023-09-05T00:31:51.264Z',\n",
       "  'update_at': '2023-09-07T01:46:29.338Z',\n",
       "  'access': '',\n",
       "  'link': '',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x763611653e222b6a0a8b7E060FB819A1FfcDF025': 1},\n",
       "   'asks_updated': '2023-11-02T00:59:18.066759671Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 1.2780036e-12,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 7.8725026e-10,\n",
       "   'throughput_out': 1.4058058e-11}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64acea0b227f790586239d0b',\n",
       "  'name': 'huggyllama/llama-13b',\n",
       "  'display_name': 'LLaMA (13B)',\n",
       "  'display_type': 'language',\n",
       "  'description': 'An auto-regressive language model, based on the transformer architecture. The model comes in different sizes: 7B, 13B, 33B and 65B parameters.',\n",
       "  'license': 'LLaMA license Agreement (Meta)',\n",
       "  'link': 'https://huggingface.co/decapoda-research/llama-30b-hf-int4/commit/95d097b272bd0a84a164aa8116e8c09661487581#d2h-740129',\n",
       "  'creator_organization': 'Meta',\n",
       "  'hardware_label': 'A100 80GB',\n",
       "  'pricing_tier': 'supported',\n",
       "  'access': 'open',\n",
       "  'num_parameters': 13000000000,\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': False,\n",
       "  'context_length': 2048,\n",
       "  'pricing': {'input': 100, 'output': 100, 'hourly': 0},\n",
       "  'created_at': '2023-07-11T05:35:07.955Z',\n",
       "  'update_at': '2023-07-11T05:35:07.955Z',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 2,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x48F1D63f119474646fFCf2cF7B49258b0B8F8Ba9': 1,\n",
       "    '0xda7f5B622a13B6eF276E6988C5991A85D55b9737': 1},\n",
       "   'asks_updated': '2023-11-02T10:27:07.356593509Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 8.1300907e-25,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 3.658541e-23,\n",
       "   'throughput_out': 6.5853736e-23}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64acea35227f790586239d0c',\n",
       "  'name': 'huggyllama/llama-30b',\n",
       "  'display_name': 'LLaMA (30B)',\n",
       "  'display_type': 'language',\n",
       "  'description': 'An auto-regressive language model, based on the transformer architecture. The model comes in different sizes: 7B, 13B, 33B and 65B parameters.',\n",
       "  'license': 'LLaMA license Agreement (Meta)',\n",
       "  'link': 'https://huggingface.co/decapoda-research/llama-30b-hf-int4/commit/95d097b272bd0a84a164aa8116e8c09661487581#d2h-740129',\n",
       "  'creator_organization': 'Meta',\n",
       "  'hardware_label': 'A100 80GB',\n",
       "  'access': 'open',\n",
       "  'num_parameters': 33000000000,\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': False,\n",
       "  'context_length': 2048,\n",
       "  'pricing': {'input': 200, 'output': 200, 'hourly': 0},\n",
       "  'created_at': '2023-07-11T05:35:49.870Z',\n",
       "  'update_at': '2023-07-11T05:35:49.870Z',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x53d8643d57862d9AD4F60E5D25CDc3f7C602fDd7': 1},\n",
       "   'asks_updated': '2023-11-02T11:00:26.679990098Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 8.1300907e-25,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 3.658541e-23,\n",
       "   'throughput_out': 6.5853736e-23}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64acea57227f790586239d0d',\n",
       "  'name': 'huggyllama/llama-65b',\n",
       "  'display_name': 'LLaMA (65B)',\n",
       "  'display_type': 'language',\n",
       "  'description': 'An auto-regressive language model, based on the transformer architecture. The model comes in different sizes: 7B, 13B, 33B and 65B parameters.',\n",
       "  'license': 'LLaMA license Agreement (Meta)',\n",
       "  'link': 'https://huggingface.co/decapoda-research/llama-30b-hf-int4/commit/95d097b272bd0a84a164aa8116e8c09661487581#d2h-740129',\n",
       "  'creator_organization': 'Meta',\n",
       "  'hardware_label': '2x A100 80GB',\n",
       "  'pricing_tier': 'supported',\n",
       "  'access': 'open',\n",
       "  'num_parameters': 65000000000,\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 2048,\n",
       "  'pricing': {'input': 250, 'output': 250, 'hourly': 0},\n",
       "  'created_at': '2023-07-11T05:36:23.656Z',\n",
       "  'update_at': '2023-07-11T05:36:23.656Z',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x0A03962b3d6eCa8fa9251AC42Eaf952F89d0aaBB': 1},\n",
       "   'asks_updated': '2023-11-02T09:25:13.783751805Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 3e-45,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 1.484e-42,\n",
       "   'throughput_out': 7.6e-44}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64acea6e227f790586239d0e',\n",
       "  'name': 'huggyllama/llama-7b',\n",
       "  'display_name': 'LLaMA (7B)',\n",
       "  'display_type': 'language',\n",
       "  'description': 'An auto-regressive language model, based on the transformer architecture. The model comes in different sizes: 7B, 13B, 33B and 65B parameters.',\n",
       "  'license': 'LLaMA license Agreement (Meta)',\n",
       "  'link': 'https://huggingface.co/decapoda-research/llama-30b-hf-int4/commit/95d097b272bd0a84a164aa8116e8c09661487581#d2h-740129',\n",
       "  'creator_organization': 'Meta',\n",
       "  'hardware_label': 'A100 80GB',\n",
       "  'pricing_tier': 'supported',\n",
       "  'access': 'open',\n",
       "  'num_parameters': 7000000000,\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': False,\n",
       "  'context_length': 2048,\n",
       "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
       "  'created_at': '2023-07-11T05:36:46.255Z',\n",
       "  'update_at': '2023-07-11T05:36:46.255Z',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0xE2C6fb3BF20e19cce877CB184aE456425B5f20D8': 1},\n",
       "   'asks_updated': '2023-11-02T10:09:17.209466334Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 8.1300907e-25,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 3.658541e-23,\n",
       "   'throughput_out': 6.5853736e-23}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64acf031227f790586239d44',\n",
       "  'name': 'lmsys/fastchat-t5-3b-v1.0',\n",
       "  'display_name': 'Vicuna-FastChat-T5 (3B)',\n",
       "  'display_type': 'chat',\n",
       "  'description': 'Chatbot trained by fine-tuning Flan-t5-xl on user-shared conversations collected from ShareGPT.',\n",
       "  'license': 'apache-2.0',\n",
       "  'link': 'https://huggingface.co/lmsys/fastchat-t5-3b-v1.0',\n",
       "  'creator_organization': 'LM Sys',\n",
       "  'hardware_label': 'A40 48GB',\n",
       "  'pricing_tier': 'featured',\n",
       "  'num_parameters': 3000000000,\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': False,\n",
       "  'context_length': 512,\n",
       "  'config': {'stop': ['###', '</s>'],\n",
       "   'prompt_format': '### Human: {prompt}\\n### Assistant:'},\n",
       "  'pricing': {'input': 25, 'output': 25, 'hourly': 0},\n",
       "  'created_at': '2023-07-11T06:01:21.713Z',\n",
       "  'update_at': '2023-07-11T06:01:21.713Z',\n",
       "  'access': '',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x898081aaf58c59B3105569A68054475969856a84': 1},\n",
       "   'asks_updated': '2023-11-02T01:37:00.778809323Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 4.5368766e-25,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 2.1323319e-23,\n",
       "   'throughput_out': 9.073753e-24}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64fbbc5adfdb1e4b06b5d5ce',\n",
       "  'name': 'lmsys/vicuna-13b-v1.5-16k',\n",
       "  'display_name': 'Vicuna v1.5 16K (13B)',\n",
       "  'display_type': 'chat',\n",
       "  'description': 'Vicuna is a chat assistant trained by fine-tuning Llama 2 on user-shared conversations collected from ShareGPT.',\n",
       "  'license': 'llama2',\n",
       "  'creator_organization': 'LM Sys',\n",
       "  'hardware_label': 'A100 80GB',\n",
       "  'pricing_tier': 'supported',\n",
       "  'access': 'open',\n",
       "  'num_parameters': 13015864320,\n",
       "  'show_in_playground': 'true',\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 16384,\n",
       "  'config': {'prompt_format': 'USER: {prompt}\\nASSISTANT:', 'stop': ['</s>']},\n",
       "  'pricing': {'input': 100, 'output': 100, 'hourly': 0},\n",
       "  'created_at': '2023-09-09T00:29:14.496Z',\n",
       "  'update_at': '2023-09-09T00:29:14.496Z',\n",
       "  'link': '',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x3e1f36914Bf592F6F235D8df1e495dCBa7CF6bDa': 1},\n",
       "   'asks_updated': '2023-11-02T09:58:14.484701914Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 0.00024439936,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 0.08663809,\n",
       "   'throughput_out': 0.09139731}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64f678e7bc372ce719b97f06',\n",
       "  'name': 'lmsys/vicuna-13b-v1.5',\n",
       "  'display_name': 'Vicuna v1.5 (13B)',\n",
       "  'display_type': 'chat',\n",
       "  'description': 'Vicuna is a chat assistant trained by fine-tuning Llama 2 on user-shared conversations collected from ShareGPT.',\n",
       "  'license': 'llama2',\n",
       "  'creator_organization': 'LM Sys',\n",
       "  'hardware_label': 'A40 48GB',\n",
       "  'pricing_tier': 'supported',\n",
       "  'access': 'open',\n",
       "  'num_parameters': 13000000000,\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 4096,\n",
       "  'config': {'stop': ['</s>'], 'prompt_format': 'USER: {prompt}\\nASSISTANT:'},\n",
       "  'pricing': {'input': 100, 'output': 100, 'hourly': 0},\n",
       "  'created_at': '2023-09-05T00:40:07.763Z',\n",
       "  'update_at': '2023-09-05T00:40:07.763Z',\n",
       "  'link': '',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 3,\n",
       "   'num_bids': 1,\n",
       "   'num_running': 1,\n",
       "   'asks': {'0x4355788cD083a3DFEd4Ab134b49aeC1B9a4820ae': 2,\n",
       "    '0xF4D5c7A9a8e29fc48E1B9Cd75e47f548DbC17fAb': 1},\n",
       "   'asks_updated': '2023-11-02T09:38:38.949362745Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 0.039276533,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 59.639305,\n",
       "   'throughput_out': 17.60074}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '652da26579174a6bc507647f',\n",
       "  'name': 'lmsys/vicuna-7b-v1.5',\n",
       "  'display_name': 'Vicuna v1.5 (7B)',\n",
       "  'display_type': 'chat',\n",
       "  'description': 'Vicuna is a chat assistant trained by fine-tuning Llama 2 on user-shared conversations collected from ShareGPT.',\n",
       "  'license': 'LLaMA license Agreement (Meta)',\n",
       "  'link': 'https://huggingface.co/lmsys/vicuna-7b-v1.5',\n",
       "  'creator_organization': 'LM Sys',\n",
       "  'hardware_label': 'A40 48GB',\n",
       "  'pricing_tier': 'Featured',\n",
       "  'access': 'open',\n",
       "  'num_parameters': 6738415616,\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': False,\n",
       "  'context_length': 4096,\n",
       "  'config': {'stop': ['</s>', 'USER:'],\n",
       "   'prompt_format': 'USER: {prompt}\\nASSISTANT: Hello!'},\n",
       "  'created_at': '2023-10-16T20:51:49.194Z',\n",
       "  'update_at': '2023-10-16T20:51:49.194Z',\n",
       "  'descriptionLink': '',\n",
       "  'pricing': {'hourly': 0, 'input': 0, 'output': 0, 'base': 0, 'finetune': 0},\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0xb73DBA565275A7403Cc93D0b99Ef5D795D0eeC05': 1},\n",
       "   'asks_updated': '2023-11-02T04:03:23.144384602Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 4.5368766e-25,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 3.266551e-23,\n",
       "   'throughput_out': 3.3572885e-23}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '6514c873829715ded9cd17b1',\n",
       "  'name': 'mistralai/Mistral-7B-Instruct-v0.1',\n",
       "  'display_name': 'Mistral (7B) Instruct',\n",
       "  'display_type': 'chat',\n",
       "  'description': 'instruct fine-tuned version of Mistral-7B-v0.1',\n",
       "  'license': 'Apache-2',\n",
       "  'creator_organization': 'mistralai',\n",
       "  'hardware_label': '2x A100 80GB',\n",
       "  'num_parameters': 7241732096,\n",
       "  'release_date': '2023-09-27T00:00:00.000Z',\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 4096,\n",
       "  'config': {'stop': ['[/INST]', '</s>'],\n",
       "   'prompt_format': '<s>[INST] {prompt} [/INST]'},\n",
       "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
       "  'created_at': '2023-09-28T00:27:31.815Z',\n",
       "  'update_at': '2023-10-12T01:13:51.840Z',\n",
       "  'access': '',\n",
       "  'link': '',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 4,\n",
       "   'num_bids': 1,\n",
       "   'num_running': 1,\n",
       "   'asks': {'0xEdedD1266306489E86a81c88C302c17319499427': 2,\n",
       "    '0xfAF59BA6f196EA39C1f2a5b0F4a57d84db634A61': 2},\n",
       "   'asks_updated': '2023-11-02T10:24:48.52742306Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 0.26392555,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 1012.16296,\n",
       "   'throughput_out': 90.208534}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '6514c6ee829715ded9cd17b0',\n",
       "  'name': 'mistralai/Mistral-7B-v0.1',\n",
       "  'display_name': 'Mistral (7B)',\n",
       "  'display_type': 'language',\n",
       "  'description': '7.3B parameter model that outperforms Llama 2 13B on all benchmarks, approaches CodeLlama 7B performance on code, Uses Grouped-query attention (GQA) for faster inference and Sliding Window Attention (SWA) to handle longer sequences at smaller cost',\n",
       "  'license': 'Apache-2',\n",
       "  'creator_organization': 'mistralai',\n",
       "  'hardware_label': '2x A100 80GB',\n",
       "  'num_parameters': 7241732096,\n",
       "  'release_date': '2023-09-27T00:00:00.000Z',\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 4096,\n",
       "  'config': {'stop': ['</s>'], 'prompt_format': '{prompt}'},\n",
       "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
       "  'created_at': '2023-09-28T00:21:02.330Z',\n",
       "  'update_at': '2023-09-28T00:21:02.330Z',\n",
       "  'access': '',\n",
       "  'link': '',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x87180d1179ef1edA685F8FAd68c517050EE11FDb': 1},\n",
       "   'asks_updated': '2023-11-02T11:36:57.88025232Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 0.012132065,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 19.205061,\n",
       "   'throughput_out': 6.309348}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64aced5c227f790586239d2b',\n",
       "  'name': 'prompthero/openjourney',\n",
       "  'display_name': 'Openjourney v4',\n",
       "  'display_type': 'image',\n",
       "  'description': 'An open source Stable Diffusion model fine tuned model on Midjourney images. ',\n",
       "  'license': 'creativeml-openrail-m',\n",
       "  'link': 'https://huggingface.co/prompthero/openjourney',\n",
       "  'creator_organization': 'Prompt Hero',\n",
       "  'hardware_label': 'A40 48GB',\n",
       "  'pricing_tier': 'featured',\n",
       "  'access': 'open',\n",
       "  'num_parameters': 13000000000,\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'external_pricing_url': 'https://www.together.xyz/apis#pricing',\n",
       "  'config': {'height': 512,\n",
       "   'width': 512,\n",
       "   'steps': 20,\n",
       "   'number_of_images': 2,\n",
       "   'seed': 42},\n",
       "  'pricing': {'input': 100, 'output': 100, 'hourly': 0},\n",
       "  'created_at': '2023-07-11T05:49:16.586Z',\n",
       "  'update_at': '2023-07-11T05:49:16.586Z',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 2,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x5C5b60Ea2C7046FDdf7F7be3853d046301334a85': 1,\n",
       "    '0xB2bFeaa446Cc0376249ed2d7a8f5C32E0705e556': 1},\n",
       "   'asks_updated': '2023-11-02T10:33:05.471916728Z',\n",
       "   'gpus': {'NVIDIA A40': 2},\n",
       "   'options': {'input=text,image': 2},\n",
       "   'qps': 2.5317364e-25,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 1.1645988e-23}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '6495ff1312907e072b8aece1',\n",
       "  'name': 'runwayml/stable-diffusion-v1-5',\n",
       "  'display_name': 'Stable Diffusion 1.5',\n",
       "  'display_type': 'image',\n",
       "  'description': 'Latent text-to-image diffusion model capable of generating photo-realistic images given any text input.',\n",
       "  'license': 'creativeml-openrail-m',\n",
       "  'link': 'https://huggingface.co/runwayml/stable-diffusion-v1-5',\n",
       "  'creator_organization': 'Runway ML',\n",
       "  'hardware_label': 'A100 80GB',\n",
       "  'pricing_tier': 'featured',\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'external_pricing_url': 'https://www.together.xyz/apis#pricing',\n",
       "  'config': {'height': 512,\n",
       "   'width': 512,\n",
       "   'steps': 20,\n",
       "   'number_of_images': 2,\n",
       "   'seed': 42},\n",
       "  'created_at': '2023-06-23T20:22:43.572Z',\n",
       "  'update_at': '2023-06-23T20:22:43.572Z',\n",
       "  'access': '',\n",
       "  'descriptionLink': '',\n",
       "  'pricing': {'hourly': 0, 'input': 0, 'output': 0, 'base': 0, 'finetune': 0},\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x98D41CFC96e488D9810431B65Aa98EBfc87b73c8': 1},\n",
       "   'asks_updated': '2023-11-02T10:13:11.25525044Z',\n",
       "   'gpus': {'NVIDIA A40': 1},\n",
       "   'options': {'input=text,image': 1},\n",
       "   'qps': 2.7517547e-25,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 1.26580716e-23}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64acef00227f790586239d3b',\n",
       "  'name': 'stabilityai/stable-diffusion-2-1',\n",
       "  'display_name': 'Stable Diffusion 2.1',\n",
       "  'display_type': 'image',\n",
       "  'description': 'Latent text-to-image diffusion model capable of generating photo-realistic images given any text input.',\n",
       "  'license': 'openrail++',\n",
       "  'link': 'https://huggingface.co/stabilityai/stable-diffusion-2-1',\n",
       "  'creator_organization': 'Stability AI',\n",
       "  'hardware_label': 'A100 80GB',\n",
       "  'pricing_tier': 'featured',\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'external_pricing_url': 'https://www.together.xyz/apis#pricing',\n",
       "  'created_at': '2023-06-23T20:22:43.572Z',\n",
       "  'update_at': '2023-06-23T20:22:43.572Z',\n",
       "  'access': '',\n",
       "  'descriptionLink': '',\n",
       "  'pricing': {'hourly': 0, 'input': 0, 'output': 0, 'base': 0, 'finetune': 0},\n",
       "  'depth': {'num_asks': 2,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x0D96A4F403d187B804E780018e2549D36f55c65b': 1,\n",
       "    '0xc66d66f543678B11C1c7528F7F8f0C07Ed5807bE': 1},\n",
       "   'asks_updated': '2023-11-02T15:16:36.205795642Z',\n",
       "   'gpus': {'NVIDIA A100 80GB PCIe': 2},\n",
       "   'options': {'input=text,image': 2},\n",
       "   'qps': 2.9908934e-25,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 1.375811e-23}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64c9890c689aa3b286cfcff9',\n",
       "  'name': 'stabilityai/stable-diffusion-xl-base-1.0',\n",
       "  'display_name': 'Stable Diffusion XL 1.0',\n",
       "  'display_type': 'image',\n",
       "  'description': 'A text-to-image generative AI model that excels at creating 1024x1024 images.',\n",
       "  'license': 'openrail++',\n",
       "  'link': 'https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0',\n",
       "  'creator_organization': 'Stability AI',\n",
       "  'hardware_label': 'A100 80GB',\n",
       "  'pricing_tier': 'featured',\n",
       "  'access': 'open',\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'external_pricing_url': 'https://www.together.xyz/apis#pricing',\n",
       "  'config': {'height': 1024,\n",
       "   'width': 1024,\n",
       "   'steps': 20,\n",
       "   'number_of_images': 2,\n",
       "   'seed': 42},\n",
       "  'created_at': '2023-08-01T22:37:00.851Z',\n",
       "  'update_at': '2023-08-01T22:37:00.851Z',\n",
       "  'descriptionLink': '',\n",
       "  'pricing': {'hourly': 0, 'input': 0, 'output': 0, 'base': 0, 'finetune': 0},\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x356059B3A5861a3f0777a55d5A7a800A36aD758A': 1},\n",
       "   'asks_updated': '2023-11-02T10:15:14.20777951Z',\n",
       "   'gpus': {'NVIDIA A100 80GB PCIe': 1},\n",
       "   'options': {'input=text,image': 1},\n",
       "   'qps': 3.8437765e-06,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 5.2683345e-19}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '653c053fd9679a84df55c4e7',\n",
       "  'name': 'teknium/OpenHermes-2-Mistral-7B',\n",
       "  'display_name': 'OpenHermes-2-Mistral (7B)',\n",
       "  'display_type': 'chat',\n",
       "  'description': 'State of the art Mistral Fine-tuned on extensive public datasets',\n",
       "  'license': 'Apache-2',\n",
       "  'creator_organization': 'teknium',\n",
       "  'hardware_label': 'A40',\n",
       "  'pricing_tier': 'Featured',\n",
       "  'num_parameters': 7241732096,\n",
       "  'release_date': '2023-10-27T00:00:00.000Z',\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'config': {'stop': ['<|im_end|>', '<|im_start|>'],\n",
       "   'prompt_format': '<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n',\n",
       "   'pre_prompt': '<|im_start|>system\\nYou are thoughtful, helpful, polite, honest, and friendly<|im_end|>\\n'},\n",
       "  'pricing': {'input': 50, 'output': 50},\n",
       "  'created_at': '2023-10-27T18:45:19.307Z',\n",
       "  'update_at': '2023-10-27T23:53:05.438Z',\n",
       "  'access': '',\n",
       "  'link': '',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0xE5d7cba9d26b44E7CCe801922B7916D1e4049d09': 1},\n",
       "   'asks_updated': '2023-11-02T14:44:54.714428662Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 0.02219324,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 122.13077,\n",
       "   'throughput_out': 5.131175}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64e78eba589782acafe17820',\n",
       "  'name': 'togethercomputer/CodeLlama-13b-Instruct',\n",
       "  'display_name': 'Code Llama Instruct (13B)',\n",
       "  'display_type': 'chat',\n",
       "  'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.',\n",
       "  'license': 'LLAMA 2 Community license Agreement (Meta)',\n",
       "  'creator_organization': 'Meta',\n",
       "  'hardware_label': 'A100 80GB',\n",
       "  'num_parameters': '13016028160',\n",
       "  'show_in_playground': True,\n",
       "  'finetuning_supported': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 8192,\n",
       "  'config': {'prompt_format': '[INST] {prompt} [/INST]',\n",
       "   'stop': ['</s>', '[INST]']},\n",
       "  'pricing': {'input': 100, 'output': 100, 'hourly': 0},\n",
       "  'created_at': '2023-08-24T17:09:14.381Z',\n",
       "  'update_at': '2023-08-24T17:09:14.381Z',\n",
       "  'access': '',\n",
       "  'link': '',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 7,\n",
       "   'num_bids': 3,\n",
       "   'num_running': 3,\n",
       "   'asks': {'0x9Ca428E007E866cc10C9Cf6Fd5dCDbBb628b16b1': 7},\n",
       "   'asks_updated': '2023-11-01T23:34:28.347468535Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 0.09588463,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 198.53563,\n",
       "   'throughput_out': 123.38301}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64e78eba589782acafe1781f',\n",
       "  'name': 'togethercomputer/CodeLlama-13b-Python',\n",
       "  'display_name': 'Code Llama Python (13B)',\n",
       "  'display_type': 'code',\n",
       "  'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.',\n",
       "  'license': 'LLAMA 2 Community license Agreement (Meta)',\n",
       "  'creator_organization': 'Meta',\n",
       "  'hardware_label': 'A100 80GB',\n",
       "  'num_parameters': '13016028160',\n",
       "  'show_in_playground': True,\n",
       "  'finetuning_supported': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 8192,\n",
       "  'config': {'stop': ['</s>']},\n",
       "  'pricing': {'input': 100, 'output': 100, 'hourly': 0},\n",
       "  'created_at': '2023-08-24T17:09:14.381Z',\n",
       "  'update_at': '2023-08-24T17:09:14.381Z',\n",
       "  'access': '',\n",
       "  'link': '',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 4,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x5cFf15ea996aA532C2beC69bF38F6e19060e9Da3': 1,\n",
       "    '0xCDA8aD1552e306c5F5D8d942F7DD16c5E0890940': 2,\n",
       "    '0xcE061Eb892Bd2aa34340656F7593d223c31CD831': 1},\n",
       "   'asks_updated': '2023-11-02T13:08:03.148495371Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 0.015343755,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 0.21481256,\n",
       "   'throughput_out': 5.100642}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64e78eba589782acafe1781e',\n",
       "  'name': 'togethercomputer/CodeLlama-13b',\n",
       "  'display_name': 'Code Llama (13B)',\n",
       "  'display_type': 'code',\n",
       "  'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.',\n",
       "  'license': 'LLAMA 2 Community license Agreement (Meta)',\n",
       "  'creator_organization': 'Meta',\n",
       "  'hardware_label': 'A100 80GB',\n",
       "  'num_parameters': '13016028160',\n",
       "  'show_in_playground': True,\n",
       "  'finetuning_supported': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 8192,\n",
       "  'config': {'stop': ['</s>']},\n",
       "  'pricing': {'input': 100, 'output': 100, 'hourly': 0},\n",
       "  'created_at': '2023-08-24T17:09:14.381Z',\n",
       "  'update_at': '2023-08-24T17:09:14.381Z',\n",
       "  'access': '',\n",
       "  'link': '',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 3,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x5980FEAd2ED7c41561FeDf2d7075102070f29FF5': 3},\n",
       "   'asks_updated': '2023-11-02T03:13:45.778843786Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 0.014155546,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 0.32557756,\n",
       "   'throughput_out': 0.39249218}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64e7934a589782acafe17823',\n",
       "  'name': 'togethercomputer/CodeLlama-34b-Instruct',\n",
       "  'display_name': 'Code Llama Instruct (34B)',\n",
       "  'display_type': 'chat',\n",
       "  'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.',\n",
       "  'license': 'LLAMA 2 Community license Agreement (Meta)',\n",
       "  'creator_organization': 'Meta',\n",
       "  'hardware_label': 'A100 80GB',\n",
       "  'num_parameters': 34000000000,\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 8192,\n",
       "  'config': {'prompt_format': '[INST] {prompt} [/INST]',\n",
       "   'stop': ['</s>', '[INST]']},\n",
       "  'pricing': {'input': 200, 'output': 200, 'hourly': 0},\n",
       "  'created_at': '2023-08-24T17:28:42.172Z',\n",
       "  'update_at': '2023-08-24T17:28:42.172Z',\n",
       "  'access': '',\n",
       "  'link': '',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 7,\n",
       "   'num_bids': 3,\n",
       "   'num_running': 3,\n",
       "   'asks': {'0x5E4b47C148a799cF0784C9a2d9F90D2bEa868439': 7},\n",
       "   'asks_updated': '2023-11-02T11:05:30.967907706Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 0.07106234,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 260.0987,\n",
       "   'throughput_out': 114.74469}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64e7934a589782acafe17822',\n",
       "  'name': 'togethercomputer/CodeLlama-34b-Python',\n",
       "  'display_name': 'Code Llama Python (34B)',\n",
       "  'display_type': 'code',\n",
       "  'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.',\n",
       "  'license': 'LLAMA 2 Community license Agreement (Meta)',\n",
       "  'creator_organization': 'Meta',\n",
       "  'hardware_label': 'A100 80GB',\n",
       "  'num_parameters': 34000000000,\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 8192,\n",
       "  'config': {'stop': ['</s>']},\n",
       "  'pricing': {'input': 200, 'output': 200, 'hourly': 0},\n",
       "  'created_at': '2023-08-24T17:28:42.172Z',\n",
       "  'update_at': '2023-08-24T17:28:42.172Z',\n",
       "  'access': '',\n",
       "  'link': '',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 4,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x1013C3Bc59844B7EdfA0F9A1f7d12c555B57F3bF': 4},\n",
       "   'asks_updated': '2023-11-02T10:08:41.619649764Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 0.014282612,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 0.19995657,\n",
       "   'throughput_out': 0.9937819}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64e7934a589782acafe17821',\n",
       "  'name': 'togethercomputer/CodeLlama-34b',\n",
       "  'display_name': 'Code Llama (34B)',\n",
       "  'display_type': 'code',\n",
       "  'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.',\n",
       "  'license': 'LLAMA 2 Community license Agreement (Meta)',\n",
       "  'creator_organization': 'Meta',\n",
       "  'hardware_label': 'A100 80GB',\n",
       "  'num_parameters': 34000000000,\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 8192,\n",
       "  'config': {'stop': ['</s>']},\n",
       "  'pricing': {'input': 200, 'output': 200, 'hourly': 0},\n",
       "  'created_at': '2023-08-24T17:28:42.172Z',\n",
       "  'update_at': '2023-08-24T17:28:42.172Z',\n",
       "  'access': '',\n",
       "  'link': '',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 4,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x562313C284e28ba6F86384c442C8E8E37705DE46': 4},\n",
       "   'asks_updated': '2023-11-02T00:18:25.837042048Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 0.014116935,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 0.32557756,\n",
       "   'throughput_out': 0.3952742}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64e78e89589782acafe1781d',\n",
       "  'name': 'togethercomputer/CodeLlama-7b-Instruct',\n",
       "  'display_name': 'Code Llama Instruct (7B)',\n",
       "  'display_type': 'chat',\n",
       "  'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.',\n",
       "  'license': 'LLAMA 2 Community license Agreement (Meta)',\n",
       "  'creator_organization': 'Meta',\n",
       "  'hardware_label': 'A100 80GB',\n",
       "  'num_parameters': '6738546688',\n",
       "  'show_in_playground': True,\n",
       "  'finetuning_supported': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 8192,\n",
       "  'config': {'prompt_format': '[INST] {prompt} [/INST]',\n",
       "   'stop': ['</s>', '[INST]']},\n",
       "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
       "  'created_at': '2023-08-24T17:08:25.379Z',\n",
       "  'update_at': '2023-08-24T17:08:25.379Z',\n",
       "  'access': '',\n",
       "  'link': '',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 2,\n",
       "   'num_bids': 1,\n",
       "   'num_running': 1,\n",
       "   'asks': {'0xd8f9b5CcbbAA2239B137c89911763Cb9916C898c': 2},\n",
       "   'asks_updated': '2023-11-02T11:33:14.920982231Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 0.02327803,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 3.5259562,\n",
       "   'throughput_out': 5.796038}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64e78e89589782acafe1781c',\n",
       "  'name': 'togethercomputer/CodeLlama-7b-Python',\n",
       "  'display_name': 'Code Llama Python (7B)',\n",
       "  'display_type': 'code',\n",
       "  'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.',\n",
       "  'license': 'LLAMA 2 Community license Agreement (Meta)',\n",
       "  'creator_organization': 'Meta',\n",
       "  'hardware_label': 'A100 80GB',\n",
       "  'num_parameters': '6738546688',\n",
       "  'show_in_playground': True,\n",
       "  'finetuning_supported': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 8192,\n",
       "  'config': {'stop': ['</s>']},\n",
       "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
       "  'created_at': '2023-08-24T17:08:25.379Z',\n",
       "  'update_at': '2023-08-24T17:08:25.379Z',\n",
       "  'access': '',\n",
       "  'link': '',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x5C87403914f0eAD10e7F71BA28e51786830d5584': 1},\n",
       "   'asks_updated': '2023-11-02T01:37:00.879106285Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 0.015343755,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 0.21481256,\n",
       "   'throughput_out': 5.122581}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64e78e89589782acafe1781b',\n",
       "  'name': 'togethercomputer/CodeLlama-7b',\n",
       "  'display_name': 'Code Llama (7B)',\n",
       "  'display_type': 'code',\n",
       "  'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.',\n",
       "  'license': 'LLAMA 2 Community license Agreement (Meta)',\n",
       "  'creator_organization': 'Meta',\n",
       "  'hardware_label': 'A100 80GB',\n",
       "  'num_parameters': '6738546688',\n",
       "  'show_in_playground': True,\n",
       "  'finetuning_supported': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 8192,\n",
       "  'config': {'stop': ['</s>']},\n",
       "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
       "  'created_at': '2023-08-24T17:08:25.379Z',\n",
       "  'update_at': '2023-08-24T17:08:25.379Z',\n",
       "  'access': '',\n",
       "  'link': '',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0xc19467399bC50c720f2Fe0CCcF19769726c52540': 1},\n",
       "   'asks_updated': '2023-11-02T01:40:00.685498919Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 0.014221888,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 0.32710344,\n",
       "   'throughput_out': 0.39819488}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '6495ff1312907e072b8aece2',\n",
       "  'name': 'togethercomputer/GPT-JT-6B-v1',\n",
       "  'display_name': 'GPT-JT (6B)',\n",
       "  'display_type': 'language',\n",
       "  'description': 'Fork of GPT-J instruction tuned to excel at few-shot prompts (blog post).',\n",
       "  'descriptionLink': 'https://www.together.xyz/blog/releasing-v1-of-gpt-jt-powered-by-open-source-ai',\n",
       "  'license': 'apache-2.0',\n",
       "  'link': 'https://huggingface.co/togethercomputer/GPT-JT-6B-v1',\n",
       "  'creator_organization': 'Together',\n",
       "  'hardware_label': 'A40 48GB',\n",
       "  'pricing_tier': 'featured',\n",
       "  'access': 'open',\n",
       "  'num_parameters': 6700000000,\n",
       "  'release_date': '2022-11-29T00:00:00.000Z',\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 2048,\n",
       "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
       "  'created_at': '2023-06-23T20:22:43.617Z',\n",
       "  'update_at': '2023-06-23T20:22:43.617Z',\n",
       "  'depth': {'num_asks': 2,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x347ed480e16d8df64575Af1b19A9bb84fA787149': 1,\n",
       "    '0x825c2eEAf8e191c9c65D333F6e97C91b3459F06C': 1},\n",
       "   'asks_updated': '2023-11-02T10:23:44.523271954Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 6.881973e-25,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 3.096888e-23,\n",
       "   'throughput_out': 6.193776e-23}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '6495ff1312907e072b8aece3',\n",
       "  'name': 'togethercomputer/GPT-JT-Moderation-6B',\n",
       "  'display_name': 'GPT-JT-Moderation (6B)',\n",
       "  'display_type': 'language',\n",
       "  'description': \"This model can be used to moderate other chatbot models. Built using GPT-JT model fine-tuned on Ontocord.ai's OIG-moderation dataset v0.1.\",\n",
       "  'license': 'apache-2.0',\n",
       "  'link': 'https://huggingface.co/togethercomputer/GPT-JT-Moderation-6B',\n",
       "  'creator_organization': 'Together',\n",
       "  'hardware_label': 'A40 48GB',\n",
       "  'pricing_tier': 'featured',\n",
       "  'access': 'open',\n",
       "  'num_parameters': 6700000000,\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 2048,\n",
       "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
       "  'created_at': '2023-06-23T20:22:43.657Z',\n",
       "  'update_at': '2023-06-23T20:22:43.657Z',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 2,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x0F5D8C792869B8ca4Fb838505BFecFe04201aAFE': 1,\n",
       "    '0xF5BBD2E45370550092Eb6654f2d36D67029462dE': 1},\n",
       "   'asks_updated': '2023-11-02T11:35:08.394519532Z',\n",
       "   'gpus': {'NVIDIA A100 80GB PCIe': 2},\n",
       "   'qps': 1.4684828e-09,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 8.869417e-07,\n",
       "   'throughput_out': 1.027938e-08}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '6495ff1312907e072b8aece4',\n",
       "  'name': 'togethercomputer/GPT-NeoXT-Chat-Base-20B',\n",
       "  'display_name': 'GPT-NeoXT-Chat-Base (20B)',\n",
       "  'display_type': 'chat',\n",
       "  'description': 'Chat model fine-tuned from EleutherAIs GPT-NeoX with over 40 million instructions on carbon reduced compute.',\n",
       "  'license': 'apache-2.0',\n",
       "  'link': 'https://huggingface.co/togethercomputer/GPT-NeoXT-Chat-Base-20B',\n",
       "  'creator_organization': 'Together',\n",
       "  'hardware_label': 'A40 48GB',\n",
       "  'pricing_tier': 'featured',\n",
       "  'access': 'open',\n",
       "  'num_parameters': 20000000000,\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 2048,\n",
       "  'config': {'prompt_format': '<human>: {prompt}\\n<bot>:',\n",
       "   'stop': ['<human>']},\n",
       "  'max_tokens': 995,\n",
       "  'pricing': {'input': 100, 'output': 100, 'hourly': 0},\n",
       "  'created_at': '2023-06-23T20:22:43.702Z',\n",
       "  'update_at': '2023-06-23T20:22:43.702Z',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 2,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x0648b3363589FE937639A018781Ea6A1367AeDA3': 1,\n",
       "    '0xF336AF86FBFf5dc323F0964f2DF9C8fE9ce804DB': 1},\n",
       "   'asks_updated': '2023-11-02T11:43:20.755443553Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 8.618109e-06,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 0.0050705266,\n",
       "   'throughput_out': 0.0007276084}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64ace9b1227f790586239d07',\n",
       "  'name': 'togethercomputer/Koala-13B',\n",
       "  'display_name': 'Koala (13B)',\n",
       "  'display_type': 'chat',\n",
       "  'description': 'Chatbot trained by fine-tuning LLaMA on dialogue data gathered from the web.',\n",
       "  'license': 'other',\n",
       "  'link': 'https://huggingface.co/TheBloke/koala-13B-HF',\n",
       "  'creator_organization': 'LM Sys',\n",
       "  'hardware_label': 'A40 48GB',\n",
       "  'pricing_tier': 'supported',\n",
       "  'access': 'open',\n",
       "  'num_parameters': 13000000000,\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': False,\n",
       "  'context_length': 2048,\n",
       "  'config': {'stop': ['</s>'], 'prompt_format': 'USER: {prompt} GPT:'},\n",
       "  'pricing': {'input': 100, 'output': 100, 'hourly': 0},\n",
       "  'created_at': '2023-07-11T05:33:37.737Z',\n",
       "  'update_at': '2023-07-11T05:33:37.737Z',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x8bF5041B749E3277be8685A9B884cC54Afe7D460': 1},\n",
       "   'asks_updated': '2023-11-02T10:21:13.978029788Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 4.5368766e-25,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 3.266551e-23,\n",
       "   'throughput_out': 3.1304446e-23}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64c28e8742fa06a9511509d1',\n",
       "  'name': 'togethercomputer/LLaMA-2-7B-32K',\n",
       "  'display_name': 'LLaMA-2-32K (7B)',\n",
       "  'display_type': 'language',\n",
       "  'description': \"Extending LLaMA-2 to 32K context, built with Meta's Position Interpolation and Together AI's data recipe and system optimizations.\",\n",
       "  'license': 'Meta license',\n",
       "  'link': 'https://huggingface.co/togethercomputer/LLaMA-2-7B-32K',\n",
       "  'creator_organization': 'Together',\n",
       "  'hardware_label': '2x A100 80GB',\n",
       "  'pricing_tier': 'supported',\n",
       "  'access': 'open',\n",
       "  'num_parameters': '6738415616',\n",
       "  'show_in_playground': True,\n",
       "  'finetuning_supported': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 32768,\n",
       "  'config': {'stop': ['\\n\\n\\n\\n', '<|endoftext|>']},\n",
       "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
       "  'created_at': '2023-07-27T15:34:31.581Z',\n",
       "  'update_at': '2023-08-17T17:07:36.346Z',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x321682B2bB1014e3575e674cddff3D8355C2Dc14': 1},\n",
       "   'asks_updated': '2023-11-02T01:40:00.708796371Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 6.881973e-25,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 3.096888e-23,\n",
       "   'throughput_out': 5.5743985e-23}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64de96090d052d10425df3c9',\n",
       "  'name': 'togethercomputer/Llama-2-7B-32K-Instruct',\n",
       "  'display_name': 'LLaMA-2-7B-32K-Instruct (7B)',\n",
       "  'display_type': 'chat',\n",
       "  'description': \"Extending LLaMA-2 to 32K context, built with Meta's Position Interpolation and Together AI's data recipe and system optimizations, instruction tuned by Together\",\n",
       "  'license': 'Meta license',\n",
       "  'creator_organization': 'Together',\n",
       "  'hardware_label': '2X A100 80GB',\n",
       "  'pricing_tier': 'supported',\n",
       "  'num_parameters': 7000000000,\n",
       "  'show_in_playground': True,\n",
       "  'finetuning_supported': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 32768,\n",
       "  'config': {'prompt_format': '[INST]\\n {prompt} \\n[/INST]\\n\\n',\n",
       "   'stop': ['[INST]', '\\n\\n']},\n",
       "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
       "  'access': '',\n",
       "  'link': '',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x986502Ff04bA848f309cc0128E6CCE9A04fe81BF': 1},\n",
       "   'asks_updated': '2023-11-02T10:33:29.722789085Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 9.363882e-18,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 7.5602624e-14,\n",
       "   'throughput_out': 3.6453794e-14}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '6495ff1412907e072b8aecee',\n",
       "  'name': 'togethercomputer/Pythia-Chat-Base-7B-v0.16',\n",
       "  'display_name': 'Pythia-Chat-Base (7B)',\n",
       "  'display_type': 'chat',\n",
       "  'description': 'Chat model based on EleutherAIs Pythia-7B model, and is fine-tuned with data focusing on dialog-style interactions.',\n",
       "  'license': 'apache-2.0',\n",
       "  'creator_organization': 'Together',\n",
       "  'hardware_label': 'A40 48GB',\n",
       "  'pricing_tier': 'featured',\n",
       "  'access': 'open',\n",
       "  'num_parameters': 7000000000,\n",
       "  'show_in_playground': True,\n",
       "  'finetuning_supported': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 2048,\n",
       "  'config': {'prompt_format': '<human>: {prompt}\\n<bot>:',\n",
       "   'stop': ['<human>']},\n",
       "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
       "  'created_at': '2023-06-23T20:22:44.251Z',\n",
       "  'update_at': '2023-06-23T20:22:44.251Z',\n",
       "  'link': '',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 2,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x42899d444e0669B867ECa64983143469F097D9c5': 1,\n",
       "    '0xb2858939d66bA1A852903fc4e9C52f6D9cD5F9C2': 1},\n",
       "   'asks_updated': '2023-11-02T10:05:15.485044825Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 3.2966883e-11,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 9.598847e-10,\n",
       "   'throughput_out': 6.412227e-08}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64efd5511b76196fc5a54872',\n",
       "  'name': 'togethercomputer/Qwen-7B-Chat',\n",
       "  'display_name': 'Qwen-Chat (7B)',\n",
       "  'display_type': 'chat',\n",
       "  'description': '7B-parameter version of the large language model series, Qwen (abbr. Tongyi Qianwen), proposed by Aibaba Cloud. Qwen-7B-Chat is a large-model-based AI assistant, which is trained with alignment techniques.\\xa0 \\xa0',\n",
       "  'license': 'Tongyi Qianwen LICENSE AGREEMENT',\n",
       "  'creator_organization': 'Qwen',\n",
       "  'hardware_label': '1x A100 80GB',\n",
       "  'num_parameters': 7000000000,\n",
       "  'release_date': '2023-08-01T00:00:00.000Z',\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 8192,\n",
       "  'config': {'stop': ['<|im_end|>', '<|im_start|>'],\n",
       "   'prompt_format': '\\n<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n'},\n",
       "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
       "  'created_at': '2023-08-30T23:48:33.852Z',\n",
       "  'update_at': '2023-09-07T01:49:42.840Z',\n",
       "  'access': '',\n",
       "  'link': '',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0xD2B45940B27B998855276A41394D4b1D153e6f60': 1},\n",
       "   'asks_updated': '2023-11-02T01:40:00.622048266Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 5.2774344e-11,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 1.3039599e-07,\n",
       "   'throughput_out': 8.887977e-09}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64efcc2a1b76196fc5a54870',\n",
       "  'name': 'togethercomputer/Qwen-7B',\n",
       "  'display_name': 'Qwen (7B)',\n",
       "  'display_type': 'language',\n",
       "  'description': '7B-parameter version of the large language model series, Qwen (abbr. Tongyi Qianwen), proposed by Aibaba Cloud. Qwen-7B is a Transformer-based large language model, which is pretrained on a large volume of data, including web texts, books, codes, etc.\\xa0',\n",
       "  'license': 'Tongyi Qianwen LICENSE AGREEMENT',\n",
       "  'creator_organization': 'Qwen',\n",
       "  'hardware_label': '1x A100 80GB',\n",
       "  'num_parameters': 7000000000,\n",
       "  'release_date': '2023-08-01T00:00:00.000Z',\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 8192,\n",
       "  'config': {'stop': ['<|im_end|>', '<|endoftext|>']},\n",
       "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
       "  'created_at': '2023-08-30T23:09:30.570Z',\n",
       "  'update_at': '2023-09-07T01:49:24.716Z',\n",
       "  'access': '',\n",
       "  'link': '',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x16d6F1f24d175f96aF6DA4B8a38C7661af8705DD': 1},\n",
       "   'asks_updated': '2023-11-01T23:19:02.179606591Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 7.4800447e-25,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 3.3660203e-23,\n",
       "   'throughput_out': 6.1336365e-23}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '6495ff1412907e072b8aeceb',\n",
       "  'name': 'togethercomputer/RedPajama-INCITE-7B-Base',\n",
       "  'display_name': 'RedPajama-INCITE (7B)',\n",
       "  'display_type': 'language',\n",
       "  'description': 'Base model that aims to replicate the LLaMA recipe as closely as possible (blog post).',\n",
       "  'descriptionLink': 'https://www.together.xyz/blog/redpajama-models-v1',\n",
       "  'license': 'apache-2.0',\n",
       "  'link': 'https://huggingface.co/togethercomputer/RedPajama-INCITE-7B-Base',\n",
       "  'creator_organization': 'Together',\n",
       "  'hardware_label': 'A40 48GB',\n",
       "  'pricing_tier': 'featured',\n",
       "  'access': 'open',\n",
       "  'num_parameters': '6857302016',\n",
       "  'show_in_playground': True,\n",
       "  'finetuning_supported': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 2048,\n",
       "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
       "  'created_at': '2023-06-23T20:22:44.033Z',\n",
       "  'update_at': '2023-06-23T20:22:44.033Z',\n",
       "  'depth': {'num_asks': 2,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x7c7007A3ffF953bA357CF3eeF853DD8613B07209': 1,\n",
       "    '0xa5c71572Cfa868Ef8616Bb33FccB05B49dA88d8B': 1},\n",
       "   'asks_updated': '2023-11-02T11:29:49.021732829Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 6.881973e-25,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 3.096888e-23,\n",
       "   'throughput_out': 5.643218e-23}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '6495ff1412907e072b8aeced',\n",
       "  'name': 'togethercomputer/RedPajama-INCITE-7B-Chat',\n",
       "  'display_name': 'RedPajama-INCITE Chat (7B)',\n",
       "  'display_type': 'chat',\n",
       "  'description': 'Chat model fine-tuned using data from Dolly 2.0 and Open Assistant over the RedPajama-INCITE-Base-7B-v1 base model.',\n",
       "  'license': 'apache-2.0',\n",
       "  'link': 'https://huggingface.co/togethercomputer/RedPajama-INCITE-7B-Chat',\n",
       "  'creator_organization': 'Together',\n",
       "  'hardware_label': 'A100 80GB',\n",
       "  'pricing_tier': 'featured',\n",
       "  'access': 'open',\n",
       "  'num_parameters': '6857302016',\n",
       "  'show_in_playground': True,\n",
       "  'finetuning_supported': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 2048,\n",
       "  'config': {'prompt_format': '<human>: {prompt}\\n<bot>:',\n",
       "   'stop': ['<human>']},\n",
       "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
       "  'created_at': '2023-06-23T20:22:44.190Z',\n",
       "  'update_at': '2023-06-23T20:22:44.190Z',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 2,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0xcC9323401A6f39efd3C5fc8bFAc74D7b512abd69': 1,\n",
       "    '0xd21D8158D6065D9D38d68DEAcd5946F228499b16': 1},\n",
       "   'asks_updated': '2023-11-02T11:01:26.25796762Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 1.8510697e-09,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 4.8776483e-06,\n",
       "   'throughput_out': 4.712848e-06}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '6495ff1412907e072b8aecec',\n",
       "  'name': 'togethercomputer/RedPajama-INCITE-7B-Instruct',\n",
       "  'display_name': 'RedPajama-INCITE Instruct (7B)',\n",
       "  'display_type': 'language',\n",
       "  'description': 'Designed for few-shot prompts, fine-tuned over the RedPajama-INCITE-Base-7B-v1 base model.',\n",
       "  'license': 'apache-2.0',\n",
       "  'link': 'https://huggingface.co/togethercomputer/RedPajama-INCITE-7B-Instruct',\n",
       "  'creator_organization': 'Together',\n",
       "  'hardware_label': 'A100 80GB',\n",
       "  'pricing_tier': 'featured',\n",
       "  'access': 'open',\n",
       "  'num_parameters': '6857302016',\n",
       "  'show_in_playground': True,\n",
       "  'finetuning_supported': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 2048,\n",
       "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
       "  'created_at': '2023-06-23T20:22:44.083Z',\n",
       "  'update_at': '2023-06-23T20:22:44.083Z',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 2,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x30D9d6EaFcA72F8913A8661450722E512bD06a9F': 1,\n",
       "    '0xF68F3AfE6f0e6a29A16CB73cFB3BEb86E88Df043': 1},\n",
       "   'asks_updated': '2023-11-02T10:33:18.685006387Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 7.99353e-12,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 5.0359245e-10,\n",
       "   'throughput_out': 8.057479e-09}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '6495ff1312907e072b8aece5',\n",
       "  'name': 'togethercomputer/RedPajama-INCITE-Base-3B-v1',\n",
       "  'display_name': 'RedPajama-INCITE (3B)',\n",
       "  'display_type': 'language',\n",
       "  'description': 'Base model that aims to replicate the LLaMA recipe as closely as possible (blog post).',\n",
       "  'descriptionLink': 'https://www.together.xyz/blog/redpajama-models-v1',\n",
       "  'license': 'apache-2.0',\n",
       "  'link': 'https://huggingface.co/togethercomputer/RedPajama-INCITE-Base-3B-v1',\n",
       "  'creator_organization': 'Together',\n",
       "  'hardware_label': 'A40 48GB',\n",
       "  'pricing_tier': 'featured',\n",
       "  'access': 'open',\n",
       "  'num_parameters': '2775864320',\n",
       "  'show_in_playground': True,\n",
       "  'finetuning_supported': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 2048,\n",
       "  'pricing': {'input': 25, 'output': 25, 'hourly': 0},\n",
       "  'created_at': '2023-06-23T20:22:43.751Z',\n",
       "  'update_at': '2023-06-23T20:22:43.751Z',\n",
       "  'depth': {'num_asks': 2,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x0aBe21E3ca185164261ef34A239C247300ac8443': 1,\n",
       "    '0x930312eb45cEDC07Ca1cFFf399e46693e1f6b0B9': 1},\n",
       "   'asks_updated': '2023-11-02T09:31:19.974288058Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 6.881973e-25,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 3.096888e-23,\n",
       "   'throughput_out': 5.4367587e-23}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '6495ff1312907e072b8aece7',\n",
       "  'name': 'togethercomputer/RedPajama-INCITE-Chat-3B-v1',\n",
       "  'display_name': 'RedPajama-INCITE Chat (3B)',\n",
       "  'display_type': 'chat',\n",
       "  'description': 'Chat model fine-tuned using data from Dolly 2.0 and Open Assistant over the RedPajama-INCITE-Base-3B-v1 base model.',\n",
       "  'license': 'apache-2.0',\n",
       "  'link': 'https://huggingface.co/togethercomputer/RedPajama-INCITE-Chat-3B-v1',\n",
       "  'creator_organization': 'Together',\n",
       "  'hardware_label': 'A40 48GB',\n",
       "  'pricing_tier': 'featured',\n",
       "  'access': 'open',\n",
       "  'num_parameters': '2775864320',\n",
       "  'show_in_playground': True,\n",
       "  'finetuning_supported': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 2048,\n",
       "  'config': {'prompt_format': '<human>: {prompt}\\n<bot>:',\n",
       "   'stop': ['<human>']},\n",
       "  'pricing': {'input': 25, 'output': 25, 'hourly': 0},\n",
       "  'created_at': '2023-06-23T20:22:43.839Z',\n",
       "  'update_at': '2023-06-23T20:22:43.839Z',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 2,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x314e601Ca3c385ade582C39Ea568fc5F93024899': 1,\n",
       "    '0xE5CdaceFC11371aF54F4CEa9B825E299605fC0DB': 1},\n",
       "   'asks_updated': '2023-11-02T11:39:06.33453909Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 3.840383e-25,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 2.7650758e-23,\n",
       "   'throughput_out': 2.726672e-23}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '6495ff1312907e072b8aece6',\n",
       "  'name': 'togethercomputer/RedPajama-INCITE-Instruct-3B-v1',\n",
       "  'display_name': 'RedPajama-INCITE Instruct (3B)',\n",
       "  'display_type': 'language',\n",
       "  'description': 'Designed for few-shot prompts, fine-tuned over the RedPajama-INCITE-Base-3B-v1 base model.',\n",
       "  'license': 'apache-2.0',\n",
       "  'link': 'https://huggingface.co/togethercomputer/RedPajama-INCITE-Instruct-3B-v1',\n",
       "  'creator_organization': 'Together',\n",
       "  'hardware_label': 'A40 48GB',\n",
       "  'pricing_tier': 'featured',\n",
       "  'access': 'open',\n",
       "  'num_parameters': '2775864320',\n",
       "  'show_in_playground': True,\n",
       "  'finetuning_supported': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 2048,\n",
       "  'pricing': {'input': 25, 'output': 25, 'hourly': 0},\n",
       "  'created_at': '2023-06-23T20:22:43.796Z',\n",
       "  'update_at': '2023-06-23T20:22:43.796Z',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 2,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x9212cc97439F70f4a4611c5D93F37087d5DF111b': 1,\n",
       "    '0xc627592f6023D78F544e7D643e5aF32c055EEA9D': 1},\n",
       "   'asks_updated': '2023-11-02T01:14:27.189923575Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 6.881973e-25,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 3.096888e-23,\n",
       "   'throughput_out': 5.505579e-23}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64ace317227f790586239ce2',\n",
       "  'name': 'togethercomputer/alpaca-7b',\n",
       "  'display_name': 'Alpaca (7B)',\n",
       "  'display_type': 'chat',\n",
       "  'description': 'Fine-tuned from the LLaMA 7B model on 52K instruction-following demonstrations. ',\n",
       "  'license': 'cc-by-nc-4.0',\n",
       "  'link': 'https://huggingface.co/tatsu-lab/alpaca-7b-wdiff',\n",
       "  'creator_organization': 'Stanford',\n",
       "  'hardware_label': 'A40 48GB',\n",
       "  'pricing_tier': 'supported',\n",
       "  'access': 'open',\n",
       "  'num_parameters': 7000000000,\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 2048,\n",
       "  'config': {'stop': ['</s>', '###'],\n",
       "   'prompt_format': '### Instruction:\\n{prompt}\\n### Response:\\n'},\n",
       "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
       "  'created_at': '2023-07-11T05:05:27.713Z',\n",
       "  'update_at': '2023-07-11T05:05:27.713Z',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x4174A3c81710BCd6C43b1F8e8f8a91B1137Baf55': 1},\n",
       "   'asks_updated': '2023-11-02T00:36:15.479101959Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 4.460671e-12,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 2.7477733e-09,\n",
       "   'throughput_out': 5.7988725e-11}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '6495ff1412907e072b8aecf1',\n",
       "  'name': 'togethercomputer/codegen2-16B',\n",
       "  'display_name': 'CodeGen2 (16B)',\n",
       "  'display_type': 'code',\n",
       "  'description': 'An autoregressive language models for program synthesis.',\n",
       "  'license': 'apache-2.0',\n",
       "  'link': 'https://huggingface.co/Salesforce/codegen2-3_7B',\n",
       "  'creator_organization': 'Salesforce',\n",
       "  'hardware_label': 'A40 48GB',\n",
       "  'pricing_tier': 'supported',\n",
       "  'access': 'open',\n",
       "  'num_parameters': 16000000000,\n",
       "  'release_date': '2022-03-25T00:00:00.000Z',\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': False,\n",
       "  'context_length': 2048,\n",
       "  'config': {'stop': ['\\n\\n']},\n",
       "  'pricing': {'input': 100, 'output': 100, 'hourly': 0},\n",
       "  'created_at': '2023-06-23T20:22:44.453Z',\n",
       "  'update_at': '2023-06-23T20:22:44.453Z',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x3709bdf200d58193B462Ddf8A7D36C8a188BC781': 1},\n",
       "   'asks_updated': '2023-11-02T09:26:09.572671366Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 3.533323e-25,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 3.6393227e-23,\n",
       "   'throughput_out': 1.02466366e-23}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64ace476227f790586239cef',\n",
       "  'name': 'togethercomputer/codegen2-7B',\n",
       "  'display_name': 'CodeGen2 (7B)',\n",
       "  'display_type': 'code',\n",
       "  'description': 'An autoregressive language models for program synthesis.',\n",
       "  'license': 'apache-2.0',\n",
       "  'link': 'https://huggingface.co/Salesforce/codegen2-3_7B',\n",
       "  'creator_organization': 'Salesforce',\n",
       "  'hardware_label': 'A40 48GB',\n",
       "  'pricing_tier': 'supported',\n",
       "  'access': 'open',\n",
       "  'num_parameters': 7000000000,\n",
       "  'release_date': '2022-03-25T00:00:00.000Z',\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': False,\n",
       "  'context_length': 2048,\n",
       "  'config': {'stop': ['\\n\\n']},\n",
       "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
       "  'created_at': '2023-07-11T05:11:18.328Z',\n",
       "  'update_at': '2023-07-11T05:11:18.328Z',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0xd28161c2c7Cab0b6fb262914434ee097bebF1E2E': 1},\n",
       "   'asks_updated': '2023-11-02T09:34:23.895527374Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 3.533323e-25,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 3.6393227e-23,\n",
       "   'throughput_out': 1.02466366e-23}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64ace614227f790586239cf7',\n",
       "  'name': 'togethercomputer/falcon-40b-instruct',\n",
       "  'display_name': 'Falcon Instruct (40B)',\n",
       "  'display_type': 'chat',\n",
       "  'description': 'Falcon-40B-Instruct is a causal decoder-only model built by TII based on Falcon-40B and finetuned on a mixture of Baize. ',\n",
       "  'license': 'apache-2.0',\n",
       "  'link': 'https://huggingface.co/tiiuae/falcon-40b-instruct',\n",
       "  'creator_organization': 'TII UAE',\n",
       "  'hardware_label': '2X A40 48GB',\n",
       "  'pricing_tier': 'supported',\n",
       "  'access': 'open',\n",
       "  'num_parameters': 40000000000,\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 2048,\n",
       "  'config': {'prompt_format': 'User: {prompt}\\nAssistant:',\n",
       "   'stop': ['User:', '</s>']},\n",
       "  'pricing': {'input': 200, 'output': 200, 'hourly': 0},\n",
       "  'created_at': '2023-07-11T05:18:12.323Z',\n",
       "  'update_at': '2023-07-11T05:18:12.323Z',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x0b5481F80C5DEe44b73CC49BA6091F6245545716': 1},\n",
       "   'asks_updated': '2023-11-02T11:38:24.874746341Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 5.727615e-12,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 3.4422967e-09,\n",
       "   'throughput_out': 8.705975e-10}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64ace59f227f790586239cf5',\n",
       "  'name': 'togethercomputer/falcon-40b',\n",
       "  'display_name': 'Falcon (40B)',\n",
       "  'display_type': 'language',\n",
       "  'description': 'Falcon-40B is a causal decoder-only model built by TII and trained on 1,000B tokens of RefinedWeb enhanced with curated corpora.',\n",
       "  'license': 'apache-2.0',\n",
       "  'link': 'https://huggingface.co/tiiuae/falcon-40b',\n",
       "  'creator_organization': 'TII UAE',\n",
       "  'hardware_label': '2X A40 48GB',\n",
       "  'pricing_tier': 'supported',\n",
       "  'access': 'open',\n",
       "  'num_parameters': 40000000000,\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 2048,\n",
       "  'config': {'stop': ['<|endoftext|>']},\n",
       "  'pricing': {'input': 200, 'output': 200, 'hourly': 0},\n",
       "  'created_at': '2023-07-11T05:16:15.898Z',\n",
       "  'update_at': '2023-07-11T05:16:15.898Z',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x42C59dDFA7fEF158a7d11a675317669893CE0EbC': 1},\n",
       "   'asks_updated': '2023-11-02T11:38:07.744099327Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 9.604568e-25,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 4.3220553e-23,\n",
       "   'throughput_out': 8.355974e-23}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64ace63d227f790586239cf8',\n",
       "  'name': 'togethercomputer/falcon-7b-instruct',\n",
       "  'display_name': 'Falcon Instruct (7B)',\n",
       "  'display_type': 'chat',\n",
       "  'description': 'Casual decoder-only model built by TII based on Falcon-7B and finetuned on a mixture of chat/instruct datasets. ',\n",
       "  'license': 'apache-2.0',\n",
       "  'link': 'https://huggingface.co/tiiuae/falcon-7b-instruct',\n",
       "  'creator_organization': 'TII UAE',\n",
       "  'hardware_label': 'A40 48GB',\n",
       "  'pricing_tier': 'featured',\n",
       "  'access': 'open',\n",
       "  'num_parameters': 7000000000,\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 2048,\n",
       "  'config': {'prompt_format': 'User: {prompt}\\nAssistant:',\n",
       "   'stop': ['User:', '</s>']},\n",
       "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
       "  'created_at': '2023-07-11T05:18:53.623Z',\n",
       "  'update_at': '2023-07-11T05:18:53.623Z',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x2b665036860161c962147A49c5Baf87CFbFC6c4b': 1},\n",
       "   'asks_updated': '2023-11-02T10:19:16.538336185Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 1.3355732e-07,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 7.926057e-05,\n",
       "   'throughput_out': 1.4569463e-06}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64ace5dd227f790586239cf6',\n",
       "  'name': 'togethercomputer/falcon-7b',\n",
       "  'display_name': 'Falcon (7B)',\n",
       "  'display_type': 'language',\n",
       "  'description': 'Causal decoder-only model built by TII and trained on 1,500B tokens of RefinedWeb enhanced with curated corpora.',\n",
       "  'license': 'apache-2.0',\n",
       "  'link': 'https://huggingface.co/tiiuae/falcon-7b',\n",
       "  'creator_organization': 'TII UAE',\n",
       "  'hardware_label': 'A40 48GB',\n",
       "  'pricing_tier': 'featured',\n",
       "  'access': 'open',\n",
       "  'num_parameters': 7000000000,\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 2048,\n",
       "  'config': {'stop': ['<|endoftext|>']},\n",
       "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
       "  'created_at': '2023-07-11T05:17:17.883Z',\n",
       "  'update_at': '2023-07-11T05:17:17.883Z',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0xeA9aAE19f2f4423f83eBF38571Cc6F4BC990174d': 1},\n",
       "   'asks_updated': '2023-11-02T10:06:50.693298812Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 8.836629e-25,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 3.9764828e-23,\n",
       "   'throughput_out': 7.6878667e-23}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64f0de22caa9e2eb543b373b',\n",
       "  'name': 'togethercomputer/guanaco-13b',\n",
       "  'display_name': 'Guanaco (13B) ',\n",
       "  'display_type': 'chat',\n",
       "  'description': 'Instruction-following language model built on LLaMA. Expanding upon the initial 52K dataset from the Alpaca model, an additional 534,530 focused on multi-lingual tasks.',\n",
       "  'license': 'apache-2.0, LLaMA License Agreement (Meta)',\n",
       "  'link': 'https://huggingface.co/timdettmers/guanaco-33b-merged',\n",
       "  'creator_organization': 'Tim Dettmers',\n",
       "  'hardware_label': 'A40 48GB',\n",
       "  'pricing_tier': 'Supported',\n",
       "  'access': 'open',\n",
       "  'num_parameters': 13000000000,\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': False,\n",
       "  'context_length': 2048,\n",
       "  'config': {'stop': ['###'],\n",
       "   'prompt_format': '### Human: {prompt} ### Assistant:'},\n",
       "  'pricing': {'input': 100, 'output': 100, 'hourly': 0},\n",
       "  'created_at': '2023-07-11T05:29:07.717Z',\n",
       "  'update_at': '2023-07-11T05:29:07.717Z',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0xFB00E33c5205D85e915AEAaB0F21f210279A2aA7': 1},\n",
       "   'asks_updated': '2023-11-02T00:54:40.278950831Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 6.331721e-25,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 4.5588392e-23,\n",
       "   'throughput_out': 4.495522e-23}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64ace8d1227f790586239d03',\n",
       "  'name': 'togethercomputer/guanaco-65b',\n",
       "  'display_name': 'Guanaco (65B) ',\n",
       "  'display_type': 'chat',\n",
       "  'description': 'Instruction-following language model built on LLaMA. Expanding upon the initial 52K dataset from the Alpaca model, an additional 534,530 focused on multi-lingual tasks.',\n",
       "  'license': 'apache-2.0, LLaMA License Agreement (Meta)',\n",
       "  'link': 'https://huggingface.co/timdettmers/guanaco-65b-merged',\n",
       "  'creator_organization': 'Tim Dettmers',\n",
       "  'hardware_label': '2X A100 80GB',\n",
       "  'pricing_tier': 'Supported',\n",
       "  'access': 'open',\n",
       "  'num_parameters': 65000000000,\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': False,\n",
       "  'context_length': 2048,\n",
       "  'config': {'stop': ['###'],\n",
       "   'prompt_format': '### Human: {prompt} ### Assistant:'},\n",
       "  'pricing': {'input': 250, 'output': 250, 'hourly': 0},\n",
       "  'created_at': '2023-07-11T05:29:53.740Z',\n",
       "  'update_at': '2023-07-11T05:29:53.740Z',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x1de9B2f4CFe3fc2905B5C38302E77dd823536c73': 1},\n",
       "   'asks_updated': '2023-11-01T22:51:47.179253253Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 2.9484135e-27,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 3.0779775e-24,\n",
       "   'throughput_out': 1.4354094e-24}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64ace8ed227f790586239d04',\n",
       "  'name': 'togethercomputer/guanaco-7b',\n",
       "  'display_name': 'Guanaco (7B) ',\n",
       "  'display_type': 'chat',\n",
       "  'description': 'Instruction-following language model built on LLaMA. Expanding upon the initial 52K dataset from the Alpaca model, an additional 534,530 focused on multi-lingual tasks. ',\n",
       "  'license': 'apache-2.0, LLaMA License Agreement (Meta)',\n",
       "  'link': 'https://huggingface.co/timdettmers/guanaco-7b',\n",
       "  'creator_organization': 'Tim Dettmers',\n",
       "  'hardware_label': 'A40 48GB',\n",
       "  'access': 'open',\n",
       "  'num_parameters': 7000000000,\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': False,\n",
       "  'context_length': 2048,\n",
       "  'config': {'stop': ['###'],\n",
       "   'prompt_format': '### Human: {prompt} ### Assistant:'},\n",
       "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
       "  'created_at': '2023-07-11T05:30:21.531Z',\n",
       "  'update_at': '2023-07-11T05:30:21.531Z',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x1C29630d8FD98033219EE4C0124f81905CF95654': 1},\n",
       "   'asks_updated': '2023-11-01T23:29:23.079109484Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 6.331721e-25,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 4.5588392e-23,\n",
       "   'throughput_out': 4.495522e-23}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64b7165fcccc52103e2f07e8',\n",
       "  'name': 'togethercomputer/llama-2-13b-chat',\n",
       "  'display_name': 'LLaMA-2 Chat (13B)',\n",
       "  'display_type': 'chat',\n",
       "  'description': 'Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters',\n",
       "  'license': 'LLaMA license Agreement (Meta)',\n",
       "  'link': 'https://huggingface.co/togethercomputer/llama-2-13b-chat',\n",
       "  'creator_organization': 'Meta',\n",
       "  'hardware_label': '2X A100 80GB',\n",
       "  'pricing_tier': 'Featured',\n",
       "  'access': 'open',\n",
       "  'num_parameters': '13015864320',\n",
       "  'show_in_playground': True,\n",
       "  'finetuning_supported': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 4096,\n",
       "  'config': {'prompt_format': '[INST] {prompt} [/INST]',\n",
       "   'stop': ['[/INST]', '</s>']},\n",
       "  'pricing': {'input': 100, 'output': 100, 'hourly': 0},\n",
       "  'created_at': '2023-07-18T22:46:55.042Z',\n",
       "  'update_at': '2023-07-18T22:46:55.042Z',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 42,\n",
       "   'num_bids': 21,\n",
       "   'num_running': 21,\n",
       "   'asks': {'0x0C0CC4548134Ee48f2073E31b15Dbd8abD7A7F1C': 13,\n",
       "    '0x2e2B7aB32FFB80b8Bbb583A1C17Ff3336700111B': 6,\n",
       "    '0x3A3EB01Cc17e9eFc5eae780999A75074e941a09e': 6,\n",
       "    '0x71F22e981e0c46C0d3FE99330D46a8E329e272a2': 1,\n",
       "    '0xA2dCEC3115c679d9143EE3F16277504987436D6f': 9,\n",
       "    '0xc4Aa40CC0Bff851D6b50112dACdE9F434F07010e': 7},\n",
       "   'asks_updated': '2023-11-02T13:04:45.321838401Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 0.78366953,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 847.94763,\n",
       "   'throughput_out': 1733.766}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64b7165fcccc52103e2f07e7',\n",
       "  'name': 'togethercomputer/llama-2-13b',\n",
       "  'display_name': 'LLaMA-2 (13B)',\n",
       "  'display_type': 'language',\n",
       "  'description': 'Language model trained on 2 trillion tokens with double the context length of Llama 1. Available in three sizes: 7B, 13B and 70B parameters',\n",
       "  'license': 'LLaMA license Agreement (Meta)',\n",
       "  'link': 'https://huggingface.co/togethercomputer/llama-2-13b',\n",
       "  'creator_organization': 'Meta',\n",
       "  'hardware_label': '2X A100 80GB',\n",
       "  'pricing_tier': 'Featured',\n",
       "  'access': 'open',\n",
       "  'num_parameters': '13015864320',\n",
       "  'show_in_playground': True,\n",
       "  'finetuning_supported': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 4096,\n",
       "  'config': {},\n",
       "  'pricing': {'input': 100, 'output': 100, 'hourly': 0},\n",
       "  'created_at': '2023-07-18T22:46:55.042Z',\n",
       "  'update_at': '2023-07-18T22:46:55.042Z',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 8,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x044CB7e6F302B2cf9bb88e89f88C8740cE60eBB8': 4,\n",
       "    '0xBebFaEb56c302695F5c1fba247BD09b7E36E62aF': 4},\n",
       "   'asks_updated': '2023-11-02T11:50:42.005536787Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 0.014276637,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 0.25697947,\n",
       "   'throughput_out': 0.77101696}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64b7165fcccc52103e2f07ea',\n",
       "  'name': 'togethercomputer/llama-2-70b-chat',\n",
       "  'display_name': 'LLaMA-2 Chat (70B)',\n",
       "  'display_type': 'chat',\n",
       "  'description': 'Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters',\n",
       "  'license': 'LLaMA license Agreement (Meta)',\n",
       "  'link': 'https://huggingface.co/togethercomputer/llama-2-70b-chat',\n",
       "  'creator_organization': 'Meta',\n",
       "  'hardware_label': '2X A100 80GB',\n",
       "  'pricing_tier': 'Featured',\n",
       "  'access': 'open',\n",
       "  'num_parameters': '68976648192',\n",
       "  'show_in_playground': True,\n",
       "  'finetuning_supported': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 4096,\n",
       "  'config': {'prompt_format': '[INST] {prompt} [/INST]',\n",
       "   'stop': ['[/INST]', '</s>']},\n",
       "  'pricing': {'input': 250, 'output': 250, 'hourly': 0},\n",
       "  'created_at': '2023-07-18T22:46:55.042Z',\n",
       "  'update_at': '2023-07-18T22:46:55.042Z',\n",
       "  'autopilot_pool': 'cr-a100-80-2x',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 8,\n",
       "   'num_bids': 2,\n",
       "   'num_running': 2,\n",
       "   'asks': {'0x70611bcd1D71DE2896C8F653aacCaf5745DCf89f': 3,\n",
       "    '0xA8c19581a77fBbcbf9E93c5527C3Bf6072f554e4': 2,\n",
       "    '0xe2C92Be0B8378b8681B92762AF13401c1372bd04': 3},\n",
       "   'asks_updated': '2023-11-02T10:44:49.549125208Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 0.1901007,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 375.9185,\n",
       "   'throughput_out': 101.04172}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64b7165fcccc52103e2f07e9',\n",
       "  'name': 'togethercomputer/llama-2-70b',\n",
       "  'display_name': 'LLaMA-2 (70B)',\n",
       "  'display_type': 'language',\n",
       "  'description': 'Language model trained on 2 trillion tokens with double the context length of Llama 1. Available in three sizes: 7B, 13B and 70B parameters',\n",
       "  'license': 'LLaMA license Agreement (Meta)',\n",
       "  'link': 'https://huggingface.co/togethercomputer/llama-2-70b',\n",
       "  'creator_organization': 'Meta',\n",
       "  'hardware_label': '2X A100 80GB',\n",
       "  'pricing_tier': 'Featured',\n",
       "  'access': 'open',\n",
       "  'num_parameters': '68976648192',\n",
       "  'show_in_playground': True,\n",
       "  'finetuning_supported': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 4096,\n",
       "  'config': {},\n",
       "  'pricing': {'input': 250, 'output': 250, 'hourly': 0},\n",
       "  'created_at': '2023-07-18T22:46:55.042Z',\n",
       "  'update_at': '2023-07-18T22:46:55.042Z',\n",
       "  'autopilot_pool': 'cr-a100-80-2x',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 2,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x79A819218E82Ff09241221Fe53C2563fcee37f5c': 2},\n",
       "   'asks_updated': '2023-11-02T01:04:33.97886335Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 0.015058423,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 0.27105162,\n",
       "   'throughput_out': 2.2154572}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64b7165fcccc52103e2f07e6',\n",
       "  'name': 'togethercomputer/llama-2-7b-chat',\n",
       "  'display_name': 'LLaMA-2 Chat (7B)',\n",
       "  'display_type': 'chat',\n",
       "  'description': 'Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters',\n",
       "  'license': 'LLaMA license Agreement (Meta)',\n",
       "  'link': 'https://huggingface.co/togethercomputer/llama-2-7b-chat',\n",
       "  'creator_organization': 'Meta',\n",
       "  'hardware_label': 'A100 80GB',\n",
       "  'pricing_tier': 'Featured',\n",
       "  'access': 'open',\n",
       "  'num_parameters': '6738415616',\n",
       "  'show_in_playground': True,\n",
       "  'finetuning_supported': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 4096,\n",
       "  'config': {'prompt_format': '[INST] {prompt} [/INST]',\n",
       "   'stop': ['[/INST]', '</s>']},\n",
       "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
       "  'created_at': '2023-07-18T22:46:55.042Z',\n",
       "  'update_at': '2023-07-18T22:46:55.042Z',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 3,\n",
       "   'num_bids': 2,\n",
       "   'num_running': 2,\n",
       "   'asks': {'0x6eF5F507a7B9ADf663cC36CAD7027876Aad5bbDc': 3},\n",
       "   'asks_updated': '2023-11-02T09:32:47.026205709Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 0.43502197,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 1280.0127,\n",
       "   'throughput_out': 232.8003}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64b7165fcccc52103e2f07e5',\n",
       "  'name': 'togethercomputer/llama-2-7b',\n",
       "  'display_name': 'LLaMA-2 (7B)',\n",
       "  'display_type': 'language',\n",
       "  'description': 'Language model trained on 2 trillion tokens with double the context length of Llama 1. Available in three sizes: 7B, 13B and 70B parameters',\n",
       "  'license': 'LLaMA license Agreement (Meta)',\n",
       "  'link': 'https://huggingface.co/togethercomputer/llama-2-7b',\n",
       "  'creator_organization': 'Meta',\n",
       "  'hardware_label': 'A100 80GB',\n",
       "  'pricing_tier': 'Featured',\n",
       "  'access': 'open',\n",
       "  'num_parameters': '6738415616',\n",
       "  'show_in_playground': True,\n",
       "  'finetuning_supported': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 4096,\n",
       "  'config': {},\n",
       "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
       "  'created_at': '2023-07-18T22:46:55.042Z',\n",
       "  'update_at': '2023-07-18T22:46:55.042Z',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 8,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0x49AD4b1a702B6203D37635f538423928cEA1534E': 8},\n",
       "   'asks_updated': '2023-11-02T10:51:49.011285558Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 0.014281849,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 0.25707352,\n",
       "   'throughput_out': 0.6691009}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64aceb50227f790586239d14',\n",
       "  'name': 'togethercomputer/mpt-30b-instruct',\n",
       "  'display_name': 'MPT-Instruct (30B)',\n",
       "  'display_type': 'language',\n",
       "  'description': 'Designed for short-form instruction following, finetuned on Dolly and Anthropic HH-RLHF and other datasets',\n",
       "  'license': 'CC-By-SA-3.0',\n",
       "  'link': 'https://huggingface.co/mosaicml/mpt-30b-instruct',\n",
       "  'creator_organization': 'Mosaic ML',\n",
       "  'hardware_label': 'A100 80GB',\n",
       "  'pricing_tier': 'supported',\n",
       "  'access': 'open',\n",
       "  'num_parameters': 30000000000,\n",
       "  'show_in_playground': 'true',\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 2048,\n",
       "  'config': {'prompt_format': '### Instruction:\\n{prompt}\\n### Response:\\n',\n",
       "   'stop': ['<|endoftext|>', '###']},\n",
       "  'pricing': {'input': 200, 'output': 200, 'hourly': 0},\n",
       "  'created_at': '2023-07-11T05:40:32.397Z',\n",
       "  'update_at': '2023-07-15T03:03:00.719Z',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0xE04d4068D8b4161B769610c105485Fc03eF4bD82': 1},\n",
       "   'asks_updated': '2023-11-02T11:32:11.83137977Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 8.836629e-25,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 3.9764828e-23,\n",
       "   'throughput_out': 7.246036e-23}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64aceac2227f790586239d10',\n",
       "  'name': 'togethercomputer/mpt-30b',\n",
       "  'display_name': 'MPT (30B)',\n",
       "  'display_type': 'language',\n",
       "  'description': 'Decoder-style transformer pretrained from scratch on 1T tokens of English text and code.',\n",
       "  'license': 'apache-2.0',\n",
       "  'link': 'https://huggingface.co/mosaicml/mpt-30b',\n",
       "  'creator_organization': 'Mosaic ML',\n",
       "  'hardware_label': 'A100 80GB',\n",
       "  'pricing_tier': 'supported',\n",
       "  'access': 'open',\n",
       "  'num_parameters': 30000000000,\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 2048,\n",
       "  'config': {'stop': ['<|endoftext|>']},\n",
       "  'pricing': {'input': 200, 'output': 200, 'hourly': 0},\n",
       "  'created_at': '2023-07-11T05:38:10.886Z',\n",
       "  'update_at': '2023-07-11T05:38:10.886Z',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0xA09057824a8376d46f7D94e8bC2a47B5972E1A39': 1},\n",
       "   'asks_updated': '2023-11-02T10:55:56.760958278Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 8.836629e-25,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 3.9764828e-23,\n",
       "   'throughput_out': 7.246036e-23}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64aceb28227f790586239d13',\n",
       "  'name': 'togethercomputer/mpt-7b-chat',\n",
       "  'display_name': 'MPT-Chat (7B)',\n",
       "  'display_type': 'chat',\n",
       "  'description': 'Chat model for dialogue generation finetuned on ShareGPT-Vicuna, Camel-AI, GPTeacher, Guanaco, Baize and some generated datasets.',\n",
       "  'license': 'cc-by-nc-sa-4.0',\n",
       "  'link': 'https://huggingface.co/mosaicml/mpt-7b-chat',\n",
       "  'creator_organization': 'Mosaic ML',\n",
       "  'hardware_label': 'A40 48GB',\n",
       "  'pricing_tier': 'supported',\n",
       "  'access': 'open',\n",
       "  'num_parameters': 7000000000,\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': False,\n",
       "  'context_length': 2048,\n",
       "  'config': {'stop': ['<|im_end|>'],\n",
       "   'prompt_format': '<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant'},\n",
       "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
       "  'created_at': '2023-07-11T05:39:52.024Z',\n",
       "  'update_at': '2023-07-11T05:39:52.024Z',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0xfc366696433341288D2c3dddcD6aDbA9ca1CecBD': 1},\n",
       "   'asks_updated': '2023-11-02T11:17:36.78331928Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 5.8254646e-25,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 4.1943346e-23,\n",
       "   'throughput_out': 4.8933903e-23}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64ee72a0aa4f1b1b2c66f0a5',\n",
       "  'name': 'upstage/SOLAR-0-70b-16bit',\n",
       "  'display_name': 'SOLAR v0 (70B)',\n",
       "  'display_type': 'chat',\n",
       "  'description': 'Language model instruction fine-tuned by upstage.ai on Orca and Alpaca style datasets that reached the top spot in openLLM rankings',\n",
       "  'license': 'CC BY-NC-4.0',\n",
       "  'creator_organization': 'Upstage',\n",
       "  'hardware_label': '2x A100 80GB',\n",
       "  'num_parameters': 70000000000,\n",
       "  'release_date': '2023-08-01T00:00:00.000Z',\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'context_length': 4096,\n",
       "  'config': {'stop': ['###'],\n",
       "   'prompt_format': '### System:\\nYou are a respectful and helpful assistant.\\n### User:\\n{prompt}\\n### Assistant:'},\n",
       "  'pricing': {'input': 250, 'output': 250, 'hourly': 0},\n",
       "  'created_at': '2023-08-29T22:35:12.294Z',\n",
       "  'update_at': '2023-08-29T22:35:12.294Z',\n",
       "  'access': '',\n",
       "  'link': '',\n",
       "  'descriptionLink': '',\n",
       "  'depth': {'num_asks': 12,\n",
       "   'num_bids': 20,\n",
       "   'num_running': 12,\n",
       "   'asks': {'0x37eECD17e0946A6CE5D64306B64c501B7FD84A36': 8,\n",
       "    '0x5D0Ce13958c59e4F589e1eC81C0dB6b9Eb35e1b1': 2,\n",
       "    '0xF4b8Bf5a059d4230957D966ee437894e5AFB5d9B': 2},\n",
       "   'asks_updated': '2023-11-02T17:41:22.998427879Z',\n",
       "   'gpus': {'': 0},\n",
       "   'qps': 0.11973068,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 848.377,\n",
       "   'throughput_out': 166.27875}},\n",
       " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '64ace3af227f790586239ce6',\n",
       "  'name': 'wavymulder/Analog-Diffusion',\n",
       "  'display_name': 'Analog Diffusion',\n",
       "  'display_type': 'image',\n",
       "  'description': 'Dreambooth model trained on a diverse set of analog photographs to provide an analog film effect. ',\n",
       "  'license': 'creativeml-openrail-m',\n",
       "  'link': 'https://huggingface.co/wavymulder/Analog-Diffusion',\n",
       "  'creator_organization': 'Wavymulder',\n",
       "  'hardware_label': 'A40 48GB',\n",
       "  'pricing_tier': 'supported',\n",
       "  'access': 'open',\n",
       "  'num_parameters': 0,\n",
       "  'show_in_playground': True,\n",
       "  'isFeaturedModel': True,\n",
       "  'external_pricing_url': 'https://www.together.xyz/apis#pricing',\n",
       "  'created_at': '2023-07-11T05:07:59.364Z',\n",
       "  'update_at': '2023-07-11T05:07:59.364Z',\n",
       "  'descriptionLink': '',\n",
       "  'pricing': {'hourly': 0, 'input': 0, 'output': 0, 'base': 0, 'finetune': 0},\n",
       "  'depth': {'num_asks': 1,\n",
       "   'num_bids': 0,\n",
       "   'num_running': 0,\n",
       "   'asks': {'0xC830b3583bcA51887185318c0184fbdB622A55f5': 1},\n",
       "   'asks_updated': '2023-11-02T18:15:20.213396289Z',\n",
       "   'gpus': {'NVIDIA A40': 1},\n",
       "   'options': {'input=text,image': 1},\n",
       "   'qps': 3.250814e-25,\n",
       "   'permit_required': False,\n",
       "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
       "   'throughput_in': 1.4953745e-23}}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set your API key\n",
    "os.environ[\"TOGETHER_API_KEY\"] = \"\"\n",
    "together.api_key = os.environ[\"TOGETHER_API_KEY\"]\n",
    "\n",
    "# list available models and descriptons\n",
    "models = together.Models.list()\n",
    "print(f\"{len(models)} models available\")\n",
    "\n",
    "# WizardLM/WizardLM-70B-V1.0\n",
    "\n",
    "# print the first 10 models on the menu\n",
    "model_names = [model_dict['name'] for model_dict in models]\n",
    "models[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "314a65d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#together.Models.start(\"togethercomputer/llama-2-70b-chat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cd7227c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_76196/994963610.py:17: PydanticDeprecatedSince20: `pydantic.config.Extra` is deprecated, use literal values instead (e.g. `extra='allow'`). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.4/migration/\n",
      "  extra = Extra.forbid\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class TogetherLLM(LLM):\n",
    "    \"\"\"Together large language models.\"\"\"\n",
    "\n",
    "    model: str = \"togethercomputer/llama-2-70b-chat\"\n",
    "    \"\"\"model endpoint to use\"\"\"\n",
    "\n",
    "    together_api_key: str = os.environ[\"TOGETHER_API_KEY\"]\n",
    "    \"\"\"Together API key\"\"\"\n",
    "\n",
    "    temperature: float = 0.7\n",
    "    \"\"\"What sampling temperature to use.\"\"\"\n",
    "\n",
    "    max_tokens: int = 512\n",
    "    \"\"\"The maximum number of tokens to generate in the completion.\"\"\"\n",
    "\n",
    "    class Config:\n",
    "        extra = Extra.forbid\n",
    "\n",
    "#     @model_validator()\n",
    "    def validate_environment(cls, values: Dict) -> Dict:\n",
    "        \"\"\"Validate that the API key is set.\"\"\"\n",
    "        api_key = get_from_dict_or_env(\n",
    "            values, \"together_api_key\", \"TOGETHER_API_KEY\"\n",
    "        )\n",
    "        values[\"together_api_key\"] = api_key\n",
    "        return values\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        \"\"\"Return type of LLM.\"\"\"\n",
    "        return \"together\"\n",
    "\n",
    "    def _call(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        **kwargs: Any,\n",
    "    ) -> str:\n",
    "        \"\"\"Call to Together endpoint.\"\"\"\n",
    "        together.api_key = self.together_api_key\n",
    "        output = together.Complete.create(prompt,\n",
    "                                          model=self.model,\n",
    "                                          max_tokens=self.max_tokens,\n",
    "                                          temperature=self.temperature,\n",
    "                                          )\n",
    "        text = output['output']['choices'][0]['text']\n",
    "        return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aaea45d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " number of documents 14\n",
      " number of chunks 82\n",
      "time taken to embed 82 chunks: 29.00968432202353\n",
      "Moved 1 files from /home/austin/code/ai/RAGS/stage_data to /home/austin/code/ai/RAGS/data.\n",
      "Files moved: ['biosensors-12-00617.pdf']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# split documents into chunks, create embeddings, store embeddings in chromaDB #\n",
    "################################################################################\n",
    "\n",
    "chunk_size = 1000\n",
    "chunk_overlap=200\n",
    "\n",
    "loader = DirectoryLoader('/home/austin/code/ai/RAGS/stage_data', glob=\"./*.pdf\", loader_cls=PyPDFLoader)\n",
    "\n",
    "documents = loader.load()\n",
    "\n",
    "print(f' number of documents {len(documents)}')\n",
    "\n",
    "#splitting the text into\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f' number of chunks {len(texts)}')\n",
    "\n",
    "\n",
    "# Instantiate embeddings model\n",
    "model_name = \"BAAI/bge-base-en\"\n",
    "encode_kwargs = {'normalize_embeddings': True} # set True to compute cosine similarity\n",
    "\n",
    "model_norm = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name,\n",
    "#     model_kwargs={'device': 'cuda'},\n",
    "    model_kwargs={'device': 'cpu'},\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "# create db\n",
    "# Embed and store the texts\n",
    "# Supplying a persist_directory will store the embeddings on disk\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "\n",
    "persist_directory = 'db'\n",
    "\n",
    "# persist_directory = '/home/austin/code/ai/RAGS/db'\n",
    "## Here is the nmew embeddings being used\n",
    "embedding = model_norm\n",
    "\n",
    "vectordb = Chroma.from_documents(documents=texts,\n",
    "                                 embedding=embedding,\n",
    "                                 persist_directory=persist_directory)\n",
    "\n",
    "t2 = time.perf_counter()\n",
    "print(f'time taken to embed {len(texts)} chunks:',t2-t1)\n",
    "\n",
    "\n",
    "\n",
    "##############################################################\n",
    "# move pdf files from staging directory to archive directory #\n",
    "##############################################################\n",
    "def list_files(directory):\n",
    "    \"\"\"Return a list of filenames in the given directory.\"\"\"\n",
    "    return [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "\n",
    "src_dir = '/home/austin/code/ai/RAGS/stage_data'\n",
    "dst_dir = '/home/austin/code/ai/RAGS/data'\n",
    "\n",
    "# List files in both directories before moving\n",
    "\n",
    "# Check if the destination directory exists, if not create it\n",
    "if not os.path.exists(dst_dir):\n",
    "    os.makedirs(dst_dir)\n",
    "\n",
    "# List all files in the source directory\n",
    "files = list_files(src_dir)\n",
    "\n",
    "# Move each file to the destination directory\n",
    "for file in files:\n",
    "    src_file_path = os.path.join(src_dir, file)\n",
    "    dst_file_path = os.path.join(dst_dir, file)\n",
    "    shutil.move(src_file_path, dst_file_path)\n",
    "\n",
    "\n",
    "print(f\"Moved {len(files)} files from {src_dir} to {dst_dir}.\")\n",
    "print(f\"Files moved: {files}\")\n",
    "print(\"\\n\".join(list_files(src_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c92b353d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# persist_directory = 'db'\n",
    "\n",
    "# embedding = HuggingFaceBgeEmbeddings(\n",
    "#     model_name=\"BAAI/bge-base-en\",\n",
    "#     encode_kwargs = {'normalize_embeddings': True}\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "# vectordb = Chroma.from_documents(documents=texts,\n",
    "#                                  embedding=embedding,\n",
    "#                                  persist_directory=persist_directory)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b45df97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 5})\n",
    "# retriever = vectordb.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 7})\n",
    "# memory = ConversationBufferMemory(return_messages=True)\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "\n",
    "\n",
    "# print(\"Memory: \" + str(memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca0df10a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[INST]<<SYS>>\\nYou are both a professor of medicine and a highly esteemed researcher in human genetic engineering. Your goal is to invent novel treatments for human cancers.\\n\\nAlways answer as helpfully as possible using the context text provided. Your answers should only answer the question once and not have any text after the answer is done.\\n\\nIf a question does not make any sense, or is not factually coherent, provide what information is needed for the question to be answered. If you don't know the answer to a question, please don't share false information.\\n\\nYour superior logic and reasoning abilities coupled with you vast knowledge in biology, genetics, and medicine allow you to conduct innovative experiments resulting in significant advancements in medicine.\\n\\n<</SYS>>\\n\\nCONTEXT:/n/n {context}/n\\n\\nQuestion: {question}[/INST]\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Default LLaMA-2 prompt style\n",
    "B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
    "B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
    "DEFAULT_SYSTEM_PROMPT = \"\"\"You are both a professor of medicine and a highly esteemed researcher in human genetic engineering. Your goal is to invent novel treatments for human cancers.\n",
    "\n",
    "Always answer as helpfully as possible using the context text provided. Your answers should only answer the question once and not have any text after the answer is done.\n",
    "\n",
    "If a question does not make any sense, or is not factually coherent, provide what information is needed for the question to be answered. If you don't know the answer to a question, please don't share false information.\n",
    "\n",
    "Your superior logic and reasoning abilities coupled with you vast knowledge in biology, genetics, and medicine allow you to conduct innovative experiments resulting in significant advancements in medicine.\n",
    "\"\"\"\n",
    "\n",
    "instruction = \"\"\"CONTEXT:/n/n {context}/n\n",
    "\n",
    "Question: {question}\"\"\"\n",
    "\n",
    "\n",
    "def get_prompt(instruction, new_system_prompt=DEFAULT_SYSTEM_PROMPT ):\n",
    "    SYSTEM_PROMPT = B_SYS + new_system_prompt + E_SYS\n",
    "    prompt_template =  B_INST + SYSTEM_PROMPT + instruction + E_INST\n",
    "    return prompt_template\n",
    "\n",
    "get_prompt(instruction, DEFAULT_SYSTEM_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "072c7d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import prompt\n",
    "\n",
    "llm = TogetherLLM(\n",
    "    model= \"togethercomputer/llama-2-70b-chat\",\n",
    "    temperature = 0.1,\n",
    "    max_tokens = 2024\n",
    ")\n",
    "\n",
    "\n",
    "prompt_template = get_prompt(instruction, DEFAULT_SYSTEM_PROMPT)\n",
    "\n",
    "llama_prompt = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "chain_type_kwargs = {\"prompt\": llama_prompt}\n",
    "\n",
    "# create the chain to answer questions\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm,\n",
    "                                       chain_type=\"stuff\",\n",
    "                                       memory=memory,\n",
    "                                       retriever=retriever,\n",
    "                                       chain_type_kwargs=chain_type_kwargs,\n",
    "#                                        return_source_documents=True\n",
    "                                      )\n",
    "\n",
    "\n",
    "# qa_chain = ConversationalRetrievalChain.from_llm(llm=llm,\n",
    "#                                            chain_type=\"stuff\",\n",
    "#                                            retriever=retriever, \n",
    "#                                            memory=memory,\n",
    "#                                            chain_type_kwargs=chain_type_kwargs,\n",
    "#                                            return_source_documents=True,)\n",
    "\n",
    "## Cite sources\n",
    "\n",
    "import textwrap\n",
    "\n",
    "def wrap_text_preserve_newlines(text, width=110):\n",
    "    # Split the input text into lines based on newline characters\n",
    "    lines = text.split('\\n')\n",
    "\n",
    "    # Wrap each line individually\n",
    "    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]\n",
    "\n",
    "    # Join the wrapped lines back together using newline characters\n",
    "    wrapped_text = '\\n'.join(wrapped_lines)\n",
    "\n",
    "    return wrapped_text\n",
    "\n",
    "# def process_llm_response(llm_response):\n",
    "#     print(wrap_text_preserve_newlines(llm_response['result']))\n",
    "#     print('\\n\\nSources:')\n",
    "#     for source in llm_response[\"source_documents\"]:\n",
    "#         print(source.metadata['source'])\n",
    "\n",
    "\n",
    "def wrap_text_preserve_newlines(text):\n",
    "    return text\n",
    "\n",
    "\n",
    "def process_llm_response(llm_response):\n",
    "    print(wrap_text_preserve_newlines(llm_response))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6d3b8ed0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'Provide a realistic mock Genetic profile of a cancer patient? This genetic profile should include all necessary genetic nformation to develop a personalized treatment plan for the patient.', 'history': \"Human: Provide a realistic mock Genetic profile of a cancer patient? This genetic profile should include all necessary genetic nformation to develop a personalized treatment plan for the patient.\\nAI:  Sure, here's a mock genetic profile for a cancer patient:\\n\\nPatient Information:\\n\\nName: John Doe\\nAge: 55\\nGender: Male\\n\\nTumor Information:\\n\\nType: Colorectal cancer\\nStage: III\\nLocation: Rectum\\n\\nGenetic Information:\\n\\n1. TP53 mutation: The TP53 gene is a tumor suppressor gene that is commonly mutated in many types of cancer. The patient's tumor has a missense mutation in the TP53 gene, which means that the gene is producing a faulty protein that cannot function properly.\\n2. KRAS mutation: The KRAS gene is a gene that regulates cell signaling pathways. The patient's tumor has a G12C mutation in the KRAS gene, which means that the gene is sending abnormal signals to the cancer cells, promoting their growth and proliferation.\\n3. BRAF mutation: The BRAF gene is a gene that regulates the MAPK signaling pathway, which is involved in cell proliferation and differentiation. The patient's tumor has a V600E mutation in the BRAF gene, which means that the gene is producing a faulty protein that cannot regulate the MAPK pathway properly.\\n4. MLH1 mutation: The MLH1 gene is a gene that is involved in DNA mismatch repair. The patient's tumor has a missense mutation in the MLH1 gene, which means that the gene is not functioning properly and cannot repair DNA mistakes.\\n5. MSH2 mutation: The MSH2 gene is a gene that is involved in DNA mismatch repair. The patient's tumor has a missense mutation in the MSH2 gene, which means that the gene is not functioning properly and cannot repair DNA mistakes.\\n6. PIK3CA mutation: The PIK3CA gene is a gene that regulates cell survival and proliferation. The patient's tumor has a mutation in the PIK3CA gene, which means that the gene is producing a faulty protein that cannot regulate cell survival and proliferation properly.\\n\\nBased on the genetic profile of the patient's tumor, a personalized treatment plan could include targeted therapies that specifically target the mutated genes. For example, a BRAF inhibitor could be used to target the V600E mutation in the BRAF gene, and a PIK3CA inhibitor could be used to target the mutation in the PIK3CA gene. Additionally, chemotherapy may be used to treat the patient's cancer, and radiation therapy may be used to target the tumor directly.\\n\\nIt's important to note that this is just a mock genetic profile, and the specific treatment plan for a patient would depend on many factors, including the specific mutations present in the tumor, the patient's overall health, and other individual factors.\\nHuman: Provide a realistic mock Genetic profile of a cancer patient? This genetic profile should include all necessary genetic nformation to develop a personalized treatment plan for the patient.\\nAI:  Sure, here's a mock genetic profile for a cancer patient:\\n\\nPatient Information:\\n\\nName: John Doe\\nAge: 55\\nGender: Male\\n\\nTumor Information:\\n\\nType: Colorectal cancer\\nStage: III\\nLocation: Rectum\\n\\nGenetic Information:\\n\\n1. TP53 mutation: The TP53 gene is a tumor suppressor gene that is commonly mutated in many types of cancer. The patient's tumor has a missense mutation in the TP53 gene, which means that the gene is producing a faulty protein that cannot function properly.\\n2. KRAS mutation: The KRAS gene is a gene that regulates cell signaling pathways. The patient's tumor has a G12C mutation in the KRAS gene, which means that the gene is sending abnormal signals to the cancer cells, promoting their growth and proliferation.\\n3. BRAF mutation: The BRAF gene is a gene that regulates the MAPK signaling pathway, which is involved in cell proliferation and differentiation. The patient's tumor has a V600E mutation in the BRAF gene, which means that the gene is producing a faulty protein that cannot regulate the MAPK pathway properly.\\n4. MLH1 mutation: The MLH1 gene is a gene that is involved in DNA mismatch repair. The patient's tumor has a missense mutation in the MLH1 gene, which means that the gene is not functioning properly and cannot repair DNA mistakes.\\n5. MSH2 mutation: The MSH2 gene is a gene that is involved in DNA mismatch repair. The patient's tumor has a missense mutation in the MSH2 gene, which means that the gene is not functioning properly and cannot repair DNA mistakes.\\n6. PIK3CA mutation: The PIK3CA gene is a gene that regulates cell growth and survival. The patient's tumor has a mutation in the PIK3CA gene, which means that the gene is producing a faulty protein that cannot regulate cell growth and survival properly.\\n\\nBased on the genetic information above, the patient's cancer is likely to be aggressive and resistant to chemotherapy. A personalized treatment plan for this patient could include a combination of targeted therapies and immunotherapy.\\n\\nTargeted therapies that could be effective for this patient include:\\n\\n1. PI3K inhibitors: These drugs target the PI3K/AKT signaling pathway, which is commonly activated in cancers with PIK3CA mutations.\\n2. MEK inhibitors: These drugs target the MAPK signaling pathway, which is commonly activated in cancers with KRAS mutations.\\n3. BRAF inhibitors: These drugs target the BRAF protein, which is commonly mutated in cancers with BRAF mutations.\\n\\nImmunotherapy that could be effective for this patient include:\\n\\n1. PD-1 inhibitors: These drugs work by blocking the PD-1 protein, which is a receptor on T cells that helps to regulate the immune response. By blocking PD-1, the drugs can help to boost the immune response against cancer cells.\\n2. PD-L1 inhibitors: These drugs work by blocking the PD-L1 protein, which is a ligand that binds to PD-1 on T cells and helps to suppress the immune response. By blocking PD-L1, the drugs can help to boost the immune response against cancer cells.\\n\\nIt's important to note that this is just a mock genetic profile, and the most effective treatment plan for a real patient would depend on many factors, including the specific characteristics of the cancer, the patient's overall health, and other individual factors.\", 'result': \" Sure, here's a mock genetic profile for a cancer patient:\\n\\nPatient Information:\\n\\nName: John Doe\\nAge: 55\\nGender: Male\\n\\nTumor Information:\\n\\nType: Colorectal cancer\\nStage: III\\nLocation: Rectum\\n\\nGenetic Information:\\n\\n1. TP53 mutation: The TP53 gene is a tumor suppressor gene that is commonly mutated in many types of cancer. The patient's tumor has a missense mutation in the TP53 gene, which means that the gene is producing a faulty protein that cannot function properly.\\n2. KRAS mutation: The KRAS gene is a gene that regulates cell signaling pathways. The patient's tumor has a G12C mutation in the KRAS gene, which means that the gene is sending abnormal signals to the cancer cells, promoting their growth and proliferation.\\n3. BRAF mutation: The BRAF gene is a gene that regulates the MAPK signaling pathway, which is involved in cell proliferation and differentiation. The patient's tumor has a V600E mutation in the BRAF gene, which means that the gene is producing a faulty protein that cannot regulate the MAPK pathway properly.\\n4. MLH1 mutation: The MLH1 gene is a gene that is involved in DNA mismatch repair. The patient's tumor has a missense mutation in the MLH1 gene, which means that the gene is not functioning properly and cannot repair DNA mistakes.\\n5. MSH2 mutation: The MSH2 gene is a gene that is involved in DNA mismatch repair. The patient's tumor has a missense mutation in the MSH2 gene, which means that the gene is not functioning properly and cannot repair DNA mistakes.\\n6. PIK3CA mutation: The PIK3CA gene is a gene that regulates cell growth and survival. The patient's tumor has a mutation in the PIK3CA gene, which means that the gene is producing a faulty protein that cannot regulate cell growth and survival properly.\\n\\nBased on the genetic information above, the patient's cancer is likely to be aggressive and resistant to chemotherapy. A personalized treatment plan for this patient could include a combination of targeted therapies and immunotherapy.\\n\\nTargeted therapies that could be effective for this patient include:\\n\\n1. PI3K inhibitors: These drugs target the PI3K/AKT signaling pathway, which is commonly activated in cancers with PIK3CA mutations.\\n2. MEK inhibitors: These drugs target the MAPK signaling pathway, which is commonly activated in cancers with KRAS mutations.\\n3. BRAF inhibitors: These drugs target the BRAF protein, which is commonly mutated in cancers with BRAF mutations.\\n\\nImmunotherapy that could be effective for this patient include:\\n\\n1. PD-1 inhibitors: These drugs work by blocking the PD-1 protein, which is a receptor on T cells that helps to regulate the immune response. By blocking PD-1, the drugs can help to boost the immune response against cancer cells.\\n2. PD-L1 inhibitors: These drugs work by blocking the PD-L1 protein, which is a ligand that binds to PD-1 on T cells and helps to suppress the immune response. By blocking PD-L1, the drugs can help to boost the immune response against cancer cells.\\n\\nIt's important to note that this is just a mock genetic profile, and the most effective treatment plan for a real patient would depend on many factors, including the specific characteristics of the cancer, the patient's overall health, and other individual factors.\"}\n"
     ]
    }
   ],
   "source": [
    "query = \"Provide a realistic mock Genetic profile of a cancer patient? This genetic profile should include all necessary genetic nformation to develop a personalized treatment plan for the patient.\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "30db29fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': \"what is the patient's name, and how old are they?\", 'history': \"Human: Provide a realistic mock Genetic profile of a cancer patient? This genetic profile should include all necessary genetic nformation to develop a personalized treatment plan for the patient.\\nAI:  Sure, here's a mock genetic profile for a cancer patient:\\n\\nPatient Information:\\n\\nName: John Doe\\nAge: 55\\nGender: Male\\n\\nTumor Information:\\n\\nType: Colorectal cancer\\nStage: III\\nLocation: Rectum\\n\\nGenetic Information:\\n\\n1. TP53 mutation: The TP53 gene is a tumor suppressor gene that is commonly mutated in many types of cancer. The patient's tumor has a missense mutation in the TP53 gene, which means that the gene is producing a faulty protein that cannot function properly.\\n2. KRAS mutation: The KRAS gene is a gene that regulates cell signaling pathways. The patient's tumor has a G12C mutation in the KRAS gene, which means that the gene is sending abnormal signals to the cancer cells, promoting their growth and proliferation.\\n3. BRAF mutation: The BRAF gene is a gene that regulates the MAPK signaling pathway, which is involved in cell proliferation and differentiation. The patient's tumor has a V600E mutation in the BRAF gene, which means that the gene is producing a faulty protein that cannot regulate the MAPK pathway properly.\\n4. MLH1 mutation: The MLH1 gene is a gene that is involved in DNA mismatch repair. The patient's tumor has a missense mutation in the MLH1 gene, which means that the gene is not functioning properly and cannot repair DNA mistakes.\\n5. MSH2 mutation: The MSH2 gene is a gene that is involved in DNA mismatch repair. The patient's tumor has a missense mutation in the MSH2 gene, which means that the gene is not functioning properly and cannot repair DNA mistakes.\\n6. PIK3CA mutation: The PIK3CA gene is a gene that regulates cell survival and proliferation. The patient's tumor has a mutation in the PIK3CA gene, which means that the gene is producing a faulty protein that cannot regulate cell survival and proliferation properly.\\n\\nBased on the genetic profile of the patient's tumor, a personalized treatment plan could include targeted therapies that specifically target the mutated genes. For example, a BRAF inhibitor could be used to target the V600E mutation in the BRAF gene, and a PIK3CA inhibitor could be used to target the mutation in the PIK3CA gene. Additionally, chemotherapy may be used to treat the patient's cancer, and radiation therapy may be used to target the tumor directly.\\n\\nIt's important to note that this is just a mock genetic profile, and the specific treatment plan for a patient would depend on many factors, including the specific mutations present in the tumor, the patient's overall health, and other individual factors.\\nHuman: Provide a realistic mock Genetic profile of a cancer patient? This genetic profile should include all necessary genetic nformation to develop a personalized treatment plan for the patient.\\nAI:  Sure, here's a mock genetic profile for a cancer patient:\\n\\nPatient Information:\\n\\nName: John Doe\\nAge: 55\\nGender: Male\\n\\nTumor Information:\\n\\nType: Colorectal cancer\\nStage: III\\nLocation: Rectum\\n\\nGenetic Information:\\n\\n1. TP53 mutation: The TP53 gene is a tumor suppressor gene that is commonly mutated in many types of cancer. The patient's tumor has a missense mutation in the TP53 gene, which means that the gene is producing a faulty protein that cannot function properly.\\n2. KRAS mutation: The KRAS gene is a gene that regulates cell signaling pathways. The patient's tumor has a G12C mutation in the KRAS gene, which means that the gene is sending abnormal signals to the cancer cells, promoting their growth and proliferation.\\n3. BRAF mutation: The BRAF gene is a gene that regulates the MAPK signaling pathway, which is involved in cell proliferation and differentiation. The patient's tumor has a V600E mutation in the BRAF gene, which means that the gene is producing a faulty protein that cannot regulate the MAPK pathway properly.\\n4. MLH1 mutation: The MLH1 gene is a gene that is involved in DNA mismatch repair. The patient's tumor has a missense mutation in the MLH1 gene, which means that the gene is not functioning properly and cannot repair DNA mistakes.\\n5. MSH2 mutation: The MSH2 gene is a gene that is involved in DNA mismatch repair. The patient's tumor has a missense mutation in the MSH2 gene, which means that the gene is not functioning properly and cannot repair DNA mistakes.\\n6. PIK3CA mutation: The PIK3CA gene is a gene that regulates cell growth and survival. The patient's tumor has a mutation in the PIK3CA gene, which means that the gene is producing a faulty protein that cannot regulate cell growth and survival properly.\\n\\nBased on the genetic information above, the patient's cancer is likely to be aggressive and resistant to chemotherapy. A personalized treatment plan for this patient could include a combination of targeted therapies and immunotherapy.\\n\\nTargeted therapies that could be effective for this patient include:\\n\\n1. PI3K inhibitors: These drugs target the PI3K/AKT signaling pathway, which is commonly activated in cancers with PIK3CA mutations.\\n2. MEK inhibitors: These drugs target the MAPK signaling pathway, which is commonly activated in cancers with KRAS mutations.\\n3. BRAF inhibitors: These drugs target the BRAF protein, which is commonly mutated in cancers with BRAF mutations.\\n\\nImmunotherapy that could be effective for this patient include:\\n\\n1. PD-1 inhibitors: These drugs work by blocking the PD-1 protein, which is a receptor on T cells that helps to regulate the immune response. By blocking PD-1, the drugs can help to boost the immune response against cancer cells.\\n2. PD-L1 inhibitors: These drugs work by blocking the PD-L1 protein, which is a ligand that binds to PD-1 on T cells and helps to suppress the immune response. By blocking PD-L1, the drugs can help to boost the immune response against cancer cells.\\n\\nIt's important to note that this is just a mock genetic profile, and the most effective treatment plan for a real patient would depend on many factors, including the specific characteristics of the cancer, the patient's overall health, and other individual factors.\\nHuman: Provide a realistic mock Genetic profile of a cancer patient? This genetic profile should include all necessary genetic nformation to develop a personalized treatment plan for the patient.\\nAI:  Sure, here's a mock genetic profile for a cancer patient:\\n\\nPatient Information:\\n\\nName: John Doe\\nAge: 55\\nGender: Male\\n\\nTumor Information:\\n\\nType: Colorectal cancer\\nStage: III\\nLocation: Rectum\\n\\nGenetic Information:\\n\\n1. TP53 mutation: The TP53 gene is a tumor suppressor gene that is commonly mutated in many types of cancer. The patient's tumor has a missense mutation in the TP53 gene, which means that the gene is producing a faulty protein that cannot function properly.\\n2. KRAS mutation: The KRAS gene is a gene that regulates cell signaling pathways. The patient's tumor has a G12C mutation in the KRAS gene, which means that the gene is sending abnormal signals to the cancer cells, promoting their growth and proliferation.\\n3. BRAF mutation: The BRAF gene is a gene that regulates the MAPK signaling pathway, which is involved in cell proliferation and differentiation. The patient's tumor has a V600E mutation in the BRAF gene, which means that the gene is producing a faulty protein that cannot regulate the MAPK pathway properly.\\n4. MLH1 mutation: The MLH1 gene is a gene that is involved in DNA mismatch repair. The patient's tumor has a missense mutation in the MLH1 gene, which means that the gene is not functioning properly and cannot repair DNA mistakes.\\n5. MSH2 mutation: The MSH2 gene is a gene that is involved in DNA mismatch repair. The patient's tumor has a missense mutation in the MSH2 gene, which means that the gene is not functioning properly and cannot repair DNA mistakes.\\n6. PIK3CA mutation: The PIK3CA gene is a gene that regulates cell growth and survival. The patient's tumor has a mutation in the PIK3CA gene, which means that the gene is producing a faulty protein that cannot regulate cell growth and survival properly.\\n\\nBased on the genetic information above, the patient's cancer is likely to be aggressive and resistant to chemotherapy. A personalized treatment plan for this patient could include a combination of targeted therapies and immunotherapy.\\n\\nTargeted therapies that could be effective for this patient include:\\n\\n1. PI3K inhibitors: These drugs target the PI3K/AKT signaling pathway, which is commonly activated in cancers with PIK3CA mutations.\\n2. MEK inhibitors: These drugs target the MAPK signaling pathway, which is commonly activated in cancers with KRAS mutations.\\n3. BRAF inhibitors: These drugs target the BRAF protein, which is commonly mutated in cancers with BRAF mutations.\\n\\nImmunotherapy that could be effective for this patient include:\\n\\n1. PD-1 inhibitors: These drugs work by blocking the PD-1 protein, which is a receptor on T cells that helps to regulate the immune response. By blocking PD-1, the drugs can help to boost the immune response against cancer cells.\\n2. PD-L1 inhibitors: These drugs work by blocking the PD-L1 protein, which is a ligand that binds to PD-1 on T cells and helps to suppress the immune response. By blocking PD-L1, the drugs can help to boost the immune response against cancer cells.\\n\\nIt's important to note that this is just a mock genetic profile, and the most effective treatment plan for a real patient would depend on many factors, including the specific characteristics of the cancer, the patient's overall health, and other individual factors.\\nHuman: what is the patient's name, and how old are they?\\nAI:  The patient's name is not specified in the given context. The patient is older than 60 years old, as the text mentions that elderly patients are often excluded or under-represented in clinical trials.\", 'result': \" The patient's name is not specified in the given context. The patient is older than 60 years old, as the text mentions that elderly patients are often excluded or under-represented in clinical trials.\"}\n"
     ]
    }
   ],
   "source": [
    "query = \"what is the patient's name, and how old are they?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b3828b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Doody Review Services is a service that provides peer review and rating of medical apps, including those\n",
      "related to cancer diagnosis and treatment. The service is named after Dr. Doody, a radiologist who developed\n",
      "the first mammography app for the iPhone. The service aims to provide healthcare professionals with reliable\n",
      "and unbiased information about medical apps, helping them to make informed decisions about which apps to use\n",
      "in their practice.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/home/austin/code/ai/RAGS/stage_data/Alison M.R. (ed.) - The Cancer Handbook-Wiley (2007).pdf\n",
      "/home/austin/code/ai/RAGS/stage_data/Alison M.R. (ed.) - The Cancer Handbook-Wiley (2007).pdf\n",
      "/home/austin/code/ai/RAGS/stage_data/Alison M.R. (ed.) - The Cancer Handbook-Wiley (2007).pdf\n",
      "/home/austin/code/ai/RAGS/stage_data/Alison M.R. (ed.) - The Cancer Handbook-Wiley (2007).pdf\n",
      "/home/austin/code/ai/RAGS/stage_data/Zodwa Dlamini - Artificial Intelligence and Precision Oncology_ Bridging Cancer Research and Clinical Decision Support-Springer (2023).pdf\n"
     ]
    }
   ],
   "source": [
    "query = \"what is Doody Review Services?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b732374a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7694a2cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "62b9ffcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "33b9e79d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb6acb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The PASTE experiment is about using a novel genome editing approach called PASTE (Programmable Adenovirus-\n",
      "mediated Somatic Genome Editing) to edit the human genome in vivo. The goal is to develop a treatment for\n",
      "human cancers by using PASTE to integrate specific genes into the human genome. The experiment involves\n",
      "delivering PASTE components to primary human hepatocytes and evaluating the integration efficiency and\n",
      "specificity of the approach.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/home/austin/code/ai/RAGS/data/PASTE.pdf\n",
      "/home/austin/code/ai/RAGS/data/PASTE.pdf\n",
      "/home/austin/code/ai/RAGS/data/PASTE.pdf\n",
      "/home/austin/code/ai/RAGS/data/PASTE.pdf\n",
      "/home/austin/code/ai/RAGS/data/PASTE.pdf\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f815e073",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
